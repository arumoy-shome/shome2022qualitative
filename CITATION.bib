@inproceedings{shome_data_2024,
	location = {New York, {NY}, {USA}},
	title = {Data vs. Model Machine Learning Fairness Testing: An Empirical Study},
	isbn = {979-8-4007-0574-8},
	url = {https://dl.acm.org/doi/10.1145/3643786.3648022},
	doi = {10.1145/3643786.3648022},
	series = {{DeepTest} '24},
	shorttitle = {Data vs. Model Machine Learning Fairness Testing},
	abstract = {Although several fairness definitions and bias mitigation techniques exist in the literature, all existing solutions evaluate fairness of Machine Learning ({ML}) systems after the training stage. In this paper, we take the first steps towards evaluating a more holistic approach by testing for fairness both before and after model training. We evaluate the effectiveness of the proposed approach and position it within the {ML} development lifecycle, using an empirical analysis of the relationship between model dependent and independent fairness metrics. The study uses 2 fairness metrics, 4 {ML} algorithms, 5 real-world datasets and 1600 fairness evaluation cycles. We find a linear relationship between data and model fairness metrics when the distribution and the size of the training data changes. Our results indicate that testing for fairness prior to training can be a "cheap" and effective means of catching a biased data collection process early; detecting data drifts in production systems and minimising execution of full training cycles thus reducing development time and costs.},
	pages = {1--8},
	booktitle = {Proceedings of the 5th {IEEE}/{ACM} International Workshop on Deep Learning for Testing and Testing for Deep Learning},
	publisher = {Association for Computing Machinery},
	author = {Shome, Arumoy and Cruz, Luis and Van Deursen, Arie},
	urldate = {2025-01-22},
	date = {2024-07-12},
	file = {Full Text PDF:/Users/aru/Documents/references/Zotero/storage/SJEBVKB6/Shome et al. - 2024 - Data vs. Model Machine Learning Fairness Testing An Empirical Study.pdf:application/pdf},
}
