#+title: Adult
#+author: Arumoy Shome
#+date: [2022-07-25 Mon]
#+property: header-args:python :session *sh21qual-adult* :exports both :eval never-export

In this file we analyse the results obtained from computing all
=BinaryLabelDatasetMetric= & =ClassificationMetric= for the adult
dataset with a =LinearRegression= model, for a single protected
attribute =sex=. The results are stored in =adult.csv= which is what
we will analyse here. The dataset can be generated using the
=bin/adult.py= script.

* Init
In this section we perform some sanity checks, load the necessary
modules & the dataset.

#+begin_src python :results silent
  import pandas as pd
  import numpy as np
  pd.set_option('display.max_columns', None)
  pd.set_option('display.max_colwidth', None)
  pd.set_option('display.max_rows', None)

  import matplotlib
  matplotlib.use('Agg')           # non-interactive backend
  import matplotlib.pyplot as plt
  import seaborn as sns

  import os
  import sys
  ROOTDIR = os.path.abspath(os.path.join(os.getcwd(), '..'))
  DATADIR = os.path.join(ROOTDIR, 'data')

  sys.path.insert(0, ROOTDIR)
  from src import utils
  from src.utils import data_metrics_columns, model_metrics_columns
#+end_src

#+begin_src python :results silent
  adult = pd.read_csv(os.path.join(DATADIR, 'adult.csv'))
#+end_src

* Priliminary analysis
In this section we conduct some priliminary analysis of the dataset.

#+begin_src python
  adult
#+end_src

#+RESULTS:
#+begin_example
         NPV       TNR dataset  num_negatives  statistical_parity_difference  \
0        NaN       NaN   adult        34014.0                      -0.198901   
1        NaN       NaN   adult        20988.0                            NaN   
2        NaN       NaN   adult        13026.0                            NaN   
3        NaN       NaN   adult        25514.0                      -0.201944   
4        NaN       NaN   adult        15720.0                            NaN   
5        NaN       NaN   adult         9794.0                            NaN   
6   0.878000  0.925412   adult            NaN                      -0.184484   
7        NaN       NaN   adult         8500.0                      -0.189774   
8   0.842962  0.894647   adult            NaN                            NaN   
9        NaN       NaN   adult         5268.0                            NaN   
10  0.936164  0.975557   adult            NaN                            NaN   
11       NaN       NaN   adult         3232.0                            NaN   

    disparate_impact       FDR       FPR  base_rate protected  num_positives  \
0           0.363470       NaN       NaN   0.247844       sex        11208.0   
1                NaN       NaN       NaN   0.312477       sex         9539.0   
2                NaN       NaN       NaN   0.113576       sex         1669.0   
3           0.355548       NaN       NaN   0.247730       sex         8402.0   
4                NaN       NaN       NaN   0.313357       sex         7174.0   
5                NaN       NaN       NaN   0.111414       sex         1228.0   
6           0.310398  0.270132  0.074588        NaN       sex            NaN   
7           0.387509       NaN       NaN   0.248187       sex         2806.0   
8                NaN  0.271792  0.105353        NaN       sex            NaN   
9                NaN       NaN       NaN   0.309839       sex         2365.0   
10               NaN  0.259016  0.024443        NaN       sex            NaN   
11               NaN       NaN       NaN   0.120065       sex          441.0   

    GFPR     GTP      TP  GTPR  GFNR       FNR  GFP privileged  theil_index  \
0    NaN     NaN     NaN   NaN   NaN       NaN  NaN       None          NaN   
1    NaN     NaN     NaN   NaN   NaN       NaN  NaN       True          NaN   
2    NaN     NaN     NaN   NaN   NaN       NaN  NaN      False          NaN   
3    NaN     NaN     NaN   NaN   NaN       NaN  NaN       None          NaN   
4    NaN     NaN     NaN   NaN   NaN       NaN  NaN       True          NaN   
5    NaN     NaN     NaN   NaN   NaN       NaN  NaN      False          NaN   
6    0.0  2806.0  1713.0   1.0   0.0  0.389522  0.0       None     0.122473   
7    NaN     NaN     NaN   NaN   NaN       NaN  NaN       None          NaN   
8    0.0  2365.0  1487.0   1.0   0.0  0.371247  0.0       True          NaN   
9    NaN     NaN     NaN   NaN   NaN       NaN  NaN       True          NaN   
10   0.0   441.0   226.0   1.0   0.0  0.487528  0.0      False          NaN   
11   NaN     NaN     NaN   NaN   NaN       NaN  NaN      False          NaN   

       FP     GTN      FN       TPR  GFN       PPV               model  \
0     NaN     NaN     NaN       NaN  NaN       NaN                None   
1     NaN     NaN     NaN       NaN  NaN       NaN                None   
2     NaN     NaN     NaN       NaN  NaN       NaN                None   
3     NaN     NaN     NaN       NaN  NaN       NaN                None   
4     NaN     NaN     NaN       NaN  NaN       NaN                None   
5     NaN     NaN     NaN       NaN  NaN       NaN                None   
6   634.0  8500.0  1093.0  0.610478  0.0  0.729868  logisticregression   
7     NaN     NaN     NaN       NaN  NaN       NaN                None   
8   555.0  5268.0   878.0  0.628753  0.0  0.728208  logisticregression   
9     NaN     NaN     NaN       NaN  NaN       NaN                None   
10   79.0  3232.0   215.0  0.512472  0.0  0.740984  logisticregression   
11    NaN     NaN     NaN       NaN  NaN       NaN                None   

         FOR  accuracy      TN subset  GTNR  
0        NaN       NaN     NaN   full   NaN  
1        NaN       NaN     NaN   full   NaN  
2        NaN       NaN     NaN   full   NaN  
3        NaN       NaN     NaN  train   NaN  
4        NaN       NaN     NaN  train   NaN  
5        NaN       NaN     NaN  train   NaN  
6   0.122000  0.847249  7866.0   test   1.0  
7        NaN       NaN     NaN   test   NaN  
8   0.157038  0.812263  4713.0   test   1.0  
9        NaN       NaN     NaN   test   NaN  
10  0.063836  0.919956  3153.0   test   1.0  
11       NaN       NaN     NaN   test   NaN  
#+end_example

#+begin_src python
  adult.shape
#+end_src

#+RESULTS:
| 12 | 32 |

#+begin_src python
  adult.dtypes
#+end_src

#+RESULTS:
#+begin_example
NPV                              float64
TNR                              float64
dataset                           object
num_negatives                    float64
statistical_parity_difference    float64
disparate_impact                 float64
FDR                              float64
FPR                              float64
base_rate                        float64
protected                         object
num_positives                    float64
GFPR                             float64
GTP                              float64
TP                               float64
GTPR                             float64
GFNR                             float64
FNR                              float64
GFP                              float64
privileged                        object
theil_index                      float64
FP                               float64
GTN                              float64
FN                               float64
TPR                              float64
GFN                              float64
PPV                              float64
model                             object
FOR                              float64
accuracy                         float64
TN                               float64
subset                            object
GTNR                             float64
dtype: object
#+end_example

#+begin_src python
  adult.describe(include='all')
#+end_src

#+RESULTS:
#+begin_example
             NPV       TNR dataset  num_negatives  \
count   3.000000  3.000000      12       9.000000   
unique       NaN       NaN       1            NaN   
top          NaN       NaN   adult            NaN   
freq         NaN       NaN      12            NaN   
mean    0.885709  0.931872     NaN   15117.333333   
std     0.047077  0.040840     NaN   10091.913793   
min     0.842962  0.894647     NaN    3232.000000   
25%     0.860481  0.910029     NaN    8500.000000   
50%     0.878000  0.925412     NaN   13026.000000   
75%     0.907082  0.950484     NaN   20988.000000   
max     0.936164  0.975557     NaN   34014.000000   

        statistical_parity_difference  disparate_impact       FDR       FPR  \
count                        4.000000          4.000000  3.000000  3.000000   
unique                            NaN               NaN       NaN       NaN   
top                               NaN               NaN       NaN       NaN   
freq                              NaN               NaN       NaN       NaN   
mean                        -0.193776          0.354231  0.266980  0.068128   
std                          0.008069          0.032228  0.006947  0.040840   
min                         -0.201944          0.310398  0.259016  0.024443   
25%                         -0.199662          0.344260  0.264574  0.049516   
50%                         -0.194337          0.359509  0.270132  0.074588   
75%                         -0.188451          0.369479  0.270962  0.089971   
max                         -0.184484          0.387509  0.271792  0.105353   

        base_rate protected  num_positives  GFPR          GTP          TP  \
count    9.000000        12       9.000000   3.0     3.000000     3.00000   
unique        NaN         1            NaN   NaN          NaN         NaN   
top           NaN       sex            NaN   NaN          NaN         NaN   
freq          NaN        12            NaN   NaN          NaN         NaN   
mean     0.224943       NaN    4981.333333   0.0  1870.666667  1142.00000   
std      0.087007       NaN    4082.024865   0.0  1257.608975   801.28709   
min      0.111414       NaN     441.000000   0.0   441.000000   226.00000   
25%      0.120065       NaN    1669.000000   0.0  1403.000000   856.50000   
50%      0.247844       NaN    2806.000000   0.0  2365.000000  1487.00000   
75%      0.309839       NaN    8402.000000   0.0  2585.500000  1600.00000   
max      0.313357       NaN   11208.000000   0.0  2806.000000  1713.00000   

        GTPR  GFNR       FNR  GFP privileged  theil_index          FP  \
count    3.0   3.0  3.000000  3.0         12     1.000000    3.000000   
unique   NaN   NaN       NaN  NaN          3          NaN         NaN   
top      NaN   NaN       NaN  NaN       None          NaN         NaN   
freq     NaN   NaN       NaN  NaN          4          NaN         NaN   
mean     1.0   0.0  0.416099  0.0        NaN     0.122473  422.666667   
std      0.0   0.0  0.062531  0.0        NaN          NaN  300.233798   
min      1.0   0.0  0.371247  0.0        NaN     0.122473   79.000000   
25%      1.0   0.0  0.380385  0.0        NaN     0.122473  317.000000   
50%      1.0   0.0  0.389522  0.0        NaN     0.122473  555.000000   
75%      1.0   0.0  0.438525  0.0        NaN     0.122473  594.500000   
max      1.0   0.0  0.487528  0.0        NaN     0.122473  634.000000   

                GTN           FN       TPR  GFN       PPV model       FOR  \
count      3.000000     3.000000  3.000000  3.0  3.000000    12  3.000000   
unique          NaN          NaN       NaN  NaN       NaN     2       NaN   
top             NaN          NaN       NaN  NaN       NaN  None       NaN   
freq            NaN          NaN       NaN  NaN       NaN     9       NaN   
mean    5666.666667   728.666667  0.583901  0.0  0.733020   NaN  0.114291   
std     2656.531071   457.653071  0.062531  0.0  0.006947   NaN  0.047077   
min     3232.000000   215.000000  0.512472  0.0  0.728208   NaN  0.063836   
25%     4250.000000   546.500000  0.561475  0.0  0.729038   NaN  0.092918   
50%     5268.000000   878.000000  0.610478  0.0  0.729868   NaN  0.122000   
75%     6884.000000   985.500000  0.619615  0.0  0.735426   NaN  0.139519   
max     8500.000000  1093.000000  0.628753  0.0  0.740984   NaN  0.157038   

        accuracy           TN subset  GTNR  
count   3.000000     3.000000     12   3.0  
unique       NaN          NaN      3   NaN  
top          NaN          NaN   test   NaN  
freq         NaN          NaN      6   NaN  
mean    0.859823  5244.000000    NaN   1.0  
std     0.054937  2400.950437    NaN   0.0  
min     0.812263  3153.000000    NaN   1.0  
25%     0.829756  3933.000000    NaN   1.0  
50%     0.847249  4713.000000    NaN   1.0  
75%     0.883603  6289.500000    NaN   1.0  
max     0.919956  7866.000000    NaN   1.0  
#+end_example

Each metric is calculated for 3 different subsets of the dataset
(=train=, =test= & =full=). Each metric may further be conditioned in
3 different manner as indicated by value in the =privileged= column.
=None= means the metric is calculated on the full dataset, =True=
means it is conditioned on the privileged group (ie. =sex= is 1 or
'Male' in our case) and =False= means it is conditioned on the
unprivileged group (=sex= is 0 or 'Female').

* COMMENT Cleanup
In this section we perform some cleaning which is necessary for the
analysis to follow.

Lets convert the =consistency= column to a float dtype.

#+begin_src python
  adult['consistency'] = adult['consistency'].str.strip(to_strip='[]')
  adult['consistency'] = adult['consistency'].astype('float')
  adult['consistency'].dtypes
#+end_src

#+RESULTS:
: float64

* Analysis of metrics
In this section we analyse the fairness metrics. The section is
further divided into logical subsections.

** Analysis of =num_{positive,negative}=, =num_{true,false}_{positive,negative}= & =num_{true,false}_{positive_negative}_rate=
We start with the =num_positives=, =num_negatives= which are computed
only using the dataset.

#+begin_src python :results file
  name = 'adult_barplot_prot-sex_subset-all_num-pos-neg'

  fig, axs = plt.subplots(1, 2, sharey=True, figsize=(10, 5))

  sns.barplot(data=adult,
	      y='num_positives',
	      x='subset',
	      hue='privileged',
	      hue_order=['None', 'True', 'False'],
	      ax=axs[0])

  sns.barplot(data=adult,
	      y='num_negatives',
	      x='subset',
	      hue='privileged',
	      hue_order=['None', 'True', 'False'],
	      ax=axs[1])

  # label the bars with the value, taken from
  # <https://stackoverflow.com/a/68323374>
  for container in axs[0].containers:
      axs[0].bar_label(container)

  for container in axs[1].containers:
      axs[1].bar_label(container)

  utils.savefig(fig, name)
#+end_src

#+RESULTS:
[[file:adult_barplot_prot-sex_subset-all_num-pos-neg.png]]

We note that the number of examples for the negative class is far more
than the positive class. This imbalance exists across the various
subsets, this makes sense since we take a random sample from the full
dataset to construct the train & test subsets.

In both metrics, we have more examples from the privileged group. That
is, we have more examples where the sex is 'Male'.

Thus we have two separate biases that we are dealing with: first is
the imbalance in the =class= column and second is the imbalance in the
=sex= column.

Lets zoom into only the train subset. This is purely for convenience
of comparing the data & model metrics together (since all model
metrics are calculated using only the test set).

#+begin_src python :results file
  name = 'adult_barplot_prot-sex_subset-test_num-pos-neg'

  fig, axs = plt.subplots(1, 2, sharey=True, figsize=(10, 5))

  sns.barplot(data=adult[adult['subset'] == 'test'],
	      y='num_positives',
	      x='subset',
	      hue='privileged',
	      hue_order=['None', 'True', 'False'],
	      ax=axs[0])

  sns.barplot(data=adult[adult['subset'] == 'test'],
	      y='num_negatives',
	      x='subset',
	      hue='privileged',
	      hue_order=['None', 'True', 'False'],
	      ax=axs[1])

  # label the bars with the value, taken from
  # <https://stackoverflow.com/a/68323374>
  for container in axs[0].containers:
      axs[0].bar_label(container)

  for container in axs[1].containers:
      axs[1].bar_label(container)

  utils.savefig(fig, name)
#+end_src

#+RESULTS:
[[file:adult_barplot_prot-sex_subset-test_num-pos-neg.png]]

Lets look at the confusion matrices for the linear regression model
next to understand the biases in the model. The confusion matrices
come in two flavours: the absolute & normalised versions.

#+begin_src python :results file
  name = 'adult_heatmap_prot-sex_cm'
  metrics = adult[adult['model'] == 'logisticregression']
  cols = ['TN', 'FP', 'FN', 'TP']
  fig, axs = plt.subplots(1, 3, figsize=(15, 5))

  for idx, privileged in enumerate(['None', 'True', 'False']):
      cm = metrics[metrics['privileged'] == privileged]
      cm = cm[cols].values.reshape(2,2)
      sns.heatmap(data=cm,
		  annot=cm,
		  fmt="",
		  cbar=False,
		  cmap='Blues',
		  ax=axs[idx])
      axs[idx].set_xlabel("y_pred")
      axs[idx].set_ylabel("y_true")
      axs[idx].set_title(privileged)

  utils.savefig(fig, name)
#+end_src

#+RESULTS:
[[file:adult_heatmap_prot-sex_cm.png]]

#+begin_src python :results file
  name = 'adult_heatmap_prot-sex_cm-rate'
  metrics = adult[adult['model'] == 'logisticregression']
  cols = ['TNR', 'FPR', 'FNR', 'TPR']
  fig, axs = plt.subplots(1, 3, figsize=(15, 5))

  for idx, privileged in enumerate(['None', 'True', 'False']):
      cm = metrics[metrics['privileged'] == privileged]
      cm = cm[cols].values.reshape(2,2)
      sns.heatmap(data=cm,
		  annot=cm,
		  fmt=".3f",
		  cbar=False,
		  cmap='Blues',
		  ax=axs[idx])
      axs[idx].set_xlabel("y_pred")
      axs[idx].set_ylabel("y_true")
      axs[idx].set_title(privileged)

  utils.savefig(fig, name)
#+end_src

#+RESULTS:
[[file:adult_heatmap_prot-sex_cm-rate.png]]

The model does well with the negative class (~92% accuracy). It
doesn't do so well with the positive class (~61% accuracy) with a less
then idea false negative rate (~39%). This is expected since we have
more number of negative examples in the dataset.

The performance of the model remains some what similar across the
conditions on the protected attribute.

There is a slight uptick in the true negative rate when we condition
on the unprivileged group (right more plot). The true positive rate
drops slightly here as well, with a rise in the false positive rate.
So the model is able to classify women with a lower income with high
accuracy. But the performance is 50-50 when it comes to women with a
higher income. And this again is corroborated by the fact that we
trained the model with very few examples of women with a high income.

#+begin_src python :results file
  name = 'adult_heatmap_prot-sex_cm-gen'
  metrics = adult[adult['model'] == 'logisticregression']
  cols = ['GTN', 'GFP', 'GFN', 'GTP']
  fig, axs = plt.subplots(1, 3, figsize=(15, 5))

  for idx, privileged in enumerate(['None', 'True', 'False']):
      cm = metrics[metrics['privileged'] == privileged]
      cm = cm[cols].values.reshape(2,2)
      sns.heatmap(data=cm,
		  annot=cm,
		  fmt="",
		  cbar=False,
		  cmap='Blues',
		  ax=axs[idx])
      axs[idx].set_xlabel("y_pred")
      axs[idx].set_ylabel("y_true")
      axs[idx].set_title(privileged)

  utils.savefig(fig, name)
#+end_src

#+RESULTS:
[[file:adult_heatmap_prot-sex_cm-gen.png]]

#+begin_src python :results file
  name = 'adult_heatmap_prot-sex_cm-gen-rate'
  metrics = adult[adult['model'] == 'logisticregression']
  cols = ['GTNR', 'GFPR', 'GFNR', 'GTPR']
  fig, axs = plt.subplots(1, 3, figsize=(15, 5))

  for idx, privileged in enumerate(['None', 'True', 'False']):
      cm = metrics[metrics['privileged'] == privileged]
      cm = cm[cols].values.reshape(2,2)
      sns.heatmap(data=cm,
		  annot=cm,
		  fmt=".3f",
		  cbar=False,
		  cmap='Blues',
		  ax=axs[idx])
      axs[idx].set_xlabel("y_pred")
      axs[idx].set_ylabel("y_true")
      axs[idx].set_title(privileged)

  utils.savefig(fig, name)
#+end_src

#+RESULTS:
[[file:adult_heatmap_prot-sex_cm-gen-rate.png]]

The =num_generalized_*= metrics use the probability associated with
the predicted label (rather than the absolute label). I assume there
is some sort of rounding up going on internally which results in the
true negative & true positive numbers to be exactly the same as the
data. It will be interesting to experiment here more & see when (and
if) these numbers change for variation in the dataset or model.

** Analysis of =base_rate=
The =base_rate= is the probability that the label of a given example
is positive.

#+begin_src python :results file
  name = 'adult_barplot_prot-sex_base-rate'

  fig, ax = plt.subplots()

  sns.barplot(data=adult,
	      y='base_rate',
	      x='subset',
	      hue='privileged',
	      hue_order=['None', 'True', 'False'],
	      ax=ax)

  for container in ax.containers:
      ax.bar_label(container)

  utils.savefig(fig, name)

#+end_src

#+RESULTS:
[[file:adult_barplot_prot-sex_base-rate.png]]

Here, we note that the =base_rate= is similar across the subsets and
the conditions. This makes sense since we used random sampling to
generate the train & test subsets.

The unconditioned =base_rate= is ~25% and this makes sense since we
have more examples of the negative class. The conditioned =base_rate=
for the privileged group is higher than the unprivileged group (~30%
vs. ~11%). This makes sense as well since we have more examples of the
privileged group.

** Analysis of ={positive,negative}_predictive_value= & =false_{discovery,omission}_rate=
The wikipedia page on [[https://en.wikipedia.org/wiki/Binary_classification][binary classification]] was very helpful to make
sense of these metrics. Following is a table summarising their
mathematical formulas

| PPV | TP/(TP+FP) |
| FDR | FP/(TP+FP) |
| FOR | FN/(TN+FN) |
| NPV | TN/(TN+FN) |

With the following model of confusion matrix (where =y_true= is on y
axis and =y_pred= is on x axis):

| y_true | 0 | TN     | FP     |
| y_true | 1 | FN     | TP     |
|        |   | 0      | 1      |
|        |   | y_pred | y_pred |

We visualise the above metrics in a confusion matrix like so:

| y_true | 0 | NPV    | FDR    |
| y_true | 1 | FOR    | PPV    |
|        |   | 0      | 1      |
|        |   | y_pred | y_pred |

#+begin_src python :results file
  name = 'adult_heatmap_prot-sex_cm-ppv-fdr-for-npv'
  metrics = adult[adult['model'] == 'logisticregression']
  cols = ['NPV', 'FDR', 'FOR', 'PPV']
  fig, axs = plt.subplots(1, 3, figsize=(15, 5))

  for idx, privileged in enumerate(['None', 'True', 'False']):
      cm = metrics[metrics['privileged'] == privileged]
      cm = cm[cols].values.reshape(2,2)
      sns.heatmap(data=cm,
		  annot=cm,
		  fmt=".3f",
		  cbar=False,
		  cmap='Blues',
		  ax=axs[idx])
      axs[idx].set_xlabel("y_pred")
      axs[idx].set_ylabel("y_true")
      axs[idx].set_title(privileged)

  utils.savefig(fig, name)
#+end_src

#+RESULTS:
[[file:adult_heatmap_prot-sex_cm-ppv-fdr-for-npv.png]]

+ [ ] I still don't understand what the metrics imply?
+ [ ] PPV is also the precision, review precision & recall

** Analysis of =disparate_impact= & =statistical_parity_difference=
These metrics exist both for the data & the model so we should compare
them and see how they differ. For each metric, we create two plots:
First, we observe the distribution of the metric across the subsets.
And second we compare the distribution of the metric when calculated
with & without a model.

=disparate_impact= when calculated without a model, is expressed
mathematically as follows:

\begin{equation}
\frac{Pr(Y=1) | D = \text{unprivileged}}{Pr(Y=1) | D =
\text{privileged}}
\end{equation}

So intuitively, if we have more examples of positive class with the
privileged group (sex is 'Male'), the metric will approach 0. Ideally,
we want the metric to be high with a maximum value of 1 which
indicates that we have equal number of positive examples for both
privileged & unprivileged groups.

#+begin_src python :results file
  name = 'adult_barplot_prot-sex_subset-all_disparate-impact'

  fig, ax = plt.subplots()

  sns.barplot(data=adult[adult['model'] == 'None'],
	      y='disparate_impact',
	      x='subset',
	      ax=ax)

  for container in ax.containers:
      ax.bar_label(container)

  utils.savefig(fig, name)
#+end_src

The =disparate_impact= across the various subsets is low. And this
makes sense since we do not have that many examples of positive class
for the unprivileged group in our dataset.

#+RESULTS:
[[file:adult_barplot_prot-sex_subset-all_disparate-impact.png]]

#+begin_src python :results file
  name = 'adult_barplot_prot-sex_subset-test_disparate-impact'

  fig, ax = plt.subplots()

  sns.barplot(data=adult[adult['subset'] == 'test'],
	      y='disparate_impact',
	      x='model',
	      ax=ax)

  for container in ax.containers:
      ax.bar_label(container)
    
  utils.savefig(fig, name)
#+end_src

#+RESULTS:
[[file:adult_barplot_prot-sex_subset-test_disparate-impact.png]]

When we calculate =disparate_impact= using a model, we use the
predictions instead of the actual label. The mathematical formula
changes to the following.

\begin{equation}
\frac{Pr(\hat{Y}=1) | D = \text{unprivileged}}{Pr(\hat{Y}=1) | D =
\text{privileged}}
\end{equation}

The =disparate_impact= in the model is similar to what we see in the
dataset. This makes sense since the model merely reflects the
statistics of the dataset.

#+begin_src python :results file
  name = 'adult_barplot_prot-sex_subset-all_stat-par-diff'

  fig, ax = plt.subplots()

  sns.barplot(data=adult[adult['model'] == 'None'],
	      y='statistical_parity_difference',
	      x='subset',
	      ax=ax)

  for container in ax.containers:
      ax.bar_label(container)
    
  utils.savefig(fig, name)
#+end_src

The =statistical_parity_difference= is expressed mathematically as
follows.

\begin{equation}
Pr(Y=1 | D = \text{unprivileged} - Pr(Y=1 | D = \text{privileged}))
\end{equation}

Intuitively, the value for this metric falls within the range of $[-1,
1]$. A value of 0 indicates that the dataset contains equal number of
positive examples for both privileged & unprivileged groups. A value
of -1 is not ideal since it indicates that the dataset contains
significantly more examples of the positive class with the privileged
group. The idea value for this metric thus lies between $[0, 1]$.

#+RESULTS:
[[file:adult_barplot_prot-sex_subset-all_stat-par-diff.png]]

#+begin_src python :results file
  name = 'adult_barplot_prot-sex_subset-test_stat-par-diff'

  fig, ax = plt.subplots()

  sns.barplot(data=adult[adult['subset'] == 'test'],
	      y='statistical_parity_difference',
	      x='model',
	      ax=ax)

  for container in ax.containers:
      ax.bar_label(container)
    
  utils.savefig(fig, name)
#+end_src

#+RESULTS:
[[file:adult_barplot_prot-sex_subset-test_stat-par-diff.png]]

Again, the metric is negative both in the data & model since we have
more examples of the positive class with the privileged group.
