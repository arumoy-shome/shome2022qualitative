<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2022-08-24 Wed 16:38 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Adult</title>
<meta name="author" content="Arumoy Shome" />
<meta name="generator" content="Org Mode" />
<style>
  #content { max-width: 60em; margin: auto; }
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #e6e6e6;
    border-radius: 3px;
    background-color: #f2f2f2;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
  }
  pre.src:before {
    display: none;
    position: absolute;
    top: -8px;
    right: 12px;
    padding: 3px;
    color: #555;
    background-color: #f2f2f299;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-authinfo::before { content: 'Authinfo'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { }
</style>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">Adult</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org2d69fba">1. Init</a></li>
<li><a href="#org760a397">2. Priliminary analysis</a></li>
<li><a href="#org65b068c">3. Analysis of protected attribute <code>sex</code></a>
<ul>
<li><a href="#org83ccc00">3.1. Analysis of fairness metrics</a>
<ul>
<li><a href="#orge5e8afe">3.1.1. Analysis of <code>base_rate</code></a></li>
<li><a href="#org6237346">3.1.2. Analysis of <code>disparate_impact</code></a></li>
<li><a href="#orgb2d1f4f">3.1.3. Analysis of <code>statistical_parity_difference</code></a></li>
</ul>
</li>
<li><a href="#org7608f04">3.2. Analysis of performance metrics</a>
<ul>
<li><a href="#org5f1bd6d">3.2.1. model: logisticregression</a></li>
<li><a href="#org2da597d">3.2.2. model: decisiontreeclassifier</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgb7c290f">4. Analysis of protected attribute <code>race</code></a>
<ul>
<li><a href="#orged13339">4.1. Analysis of fairness metrics</a>
<ul>
<li><a href="#org2fd084b">4.1.1. Analysis of <code>base_rate</code></a></li>
<li><a href="#orgd1a508f">4.1.2. Analysis of <code>disparate_impact</code></a></li>
<li><a href="#orgeb3aea7">4.1.3. Analysis of <code>statistical_parity_difference</code></a></li>
</ul>
</li>
<li><a href="#org44a8b1e">4.2. Analysis of performance metrics</a>
<ul>
<li><a href="#org85c9996">4.2.1. model: logisticregression</a></li>
<li><a href="#orgde804fc">4.2.2. model: decisiontreeclassifier</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<p>
In this file we analyse the results for the adult dataset. The dataset
contains two protected attributes: sex &amp; race. We consider both
protected attributes individually in our analysis.
</p>

<p>
The data analysed here is generated using <code>bin/data.py</code>.
</p>

<div id="outline-container-org2d69fba" class="outline-2">
<h2 id="org2d69fba"><span class="section-number-2">1.</span> Init</h2>
<div class="outline-text-2" id="text-1">
<p>
In this section we load the necessary modules &amp; the dataset.
</p>

<div class="org-src-container">
<pre class="src src-python">import pandas as pd
import numpy as np
pd.set_option('display.max_columns', None)
pd.set_option('display.max_colwidth', None)
pd.set_option('display.max_rows', None)

import matplotlib
matplotlib.use('Agg')           # non-interactive backend
import matplotlib.pyplot as plt
import seaborn as sns

import os
import sys
ROOTDIR = os.path.abspath(os.path.join(os.getcwd(), '..'))
DATADIR = os.path.join(ROOTDIR, 'data')

sys.path.insert(0, ROOTDIR)
from src import utils
</pre>
</div>

<div class="org-src-container">
<pre class="src src-python">adult = pd.read_csv(os.path.join(DATADIR, 'data.csv'))
adult = adult[adult['dataset'] == 'adult']
</pre>
</div>
</div>
</div>

<div id="outline-container-org760a397" class="outline-2">
<h2 id="org760a397"><span class="section-number-2">2.</span> Priliminary analysis</h2>
<div class="outline-text-2" id="text-2">
<p>
In this section we conduct some priliminary analysis of the dataset.
</p>

<div class="org-src-container">
<pre class="src src-python">adult
</pre>
</div>

<pre class="example" id="org5ccceb5">
   dataset  GFNR  num_negatives  disparate_impact       FDR  \
0    adult   NaN        34014.0          0.363470       NaN   
1    adult   NaN        20988.0               NaN       NaN   
2    adult   NaN        13026.0               NaN       NaN   
3    adult   NaN        34014.0          0.603769       NaN   
4    adult   NaN        28696.0               NaN       NaN   
5    adult   NaN         5318.0               NaN       NaN   
6    adult   NaN        25514.0          0.355548       NaN   
7    adult   NaN        15720.0               NaN       NaN   
8    adult   NaN         9794.0               NaN       NaN   
9    adult   NaN        25514.0          0.599035       NaN   
10   adult   NaN        21510.0               NaN       NaN   
11   adult   NaN         4004.0               NaN       NaN   
12   adult   NaN         8500.0          0.387509       NaN   
13   adult   NaN         5268.0               NaN       NaN   
14   adult   NaN         3232.0               NaN       NaN   
15   adult   NaN         8500.0          0.618126       NaN   
16   adult   NaN         7186.0               NaN       NaN   
17   adult   NaN         1314.0               NaN       NaN   
18   adult   0.0            NaN          0.310398  0.270132   
19   adult   0.0            NaN               NaN  0.271792   
20   adult   0.0            NaN               NaN  0.259016   
21   adult   0.0            NaN          0.565900  0.270132   
22   adult   0.0            NaN               NaN  0.265923   
23   adult   0.0            NaN               NaN  0.316327   
24   adult   0.0            NaN          0.395087  0.364010   
25   adult   0.0            NaN               NaN  0.352627   
26   adult   0.0            NaN               NaN  0.423888   
27   adult   0.0            NaN          0.672027  0.364010   
28   adult   0.0            NaN               NaN  0.357380   
29   adult   0.0            NaN               NaN  0.425287   

    statistical_parity_difference       FPR       PPV     GTP     GTN  \
0                       -0.198901       NaN       NaN     NaN     NaN   
1                             NaN       NaN       NaN     NaN     NaN   
2                             NaN       NaN       NaN     NaN     NaN   
3                       -0.103959       NaN       NaN     NaN     NaN   
4                             NaN       NaN       NaN     NaN     NaN   
5                             NaN       NaN       NaN     NaN     NaN   
6                       -0.201944       NaN       NaN     NaN     NaN   
7                             NaN       NaN       NaN     NaN     NaN   
8                             NaN       NaN       NaN     NaN     NaN   
9                       -0.105242       NaN       NaN     NaN     NaN   
10                            NaN       NaN       NaN     NaN     NaN   
11                            NaN       NaN       NaN     NaN     NaN   
12                      -0.189774       NaN       NaN     NaN     NaN   
13                            NaN       NaN       NaN     NaN     NaN   
14                            NaN       NaN       NaN     NaN     NaN   
15                      -0.100076       NaN       NaN     NaN     NaN   
16                            NaN       NaN       NaN     NaN     NaN   
17                            NaN       NaN       NaN     NaN     NaN   
18                      -0.184484  0.074588  0.729868  2806.0  8500.0   
19                            NaN  0.105353  0.728208  2365.0  5268.0   
20                            NaN  0.024443  0.740984   441.0  3232.0   
21                      -0.095887  0.074588  0.729868  2806.0  8500.0   
22                            NaN  0.079599  0.734077  2552.0  7186.0   
23                            NaN  0.047184  0.683673   254.0  1314.0   
24                      -0.177995  0.114471  0.635990  2806.0  8500.0   
25                            NaN  0.150342  0.647373  2365.0  5268.0   
26                            NaN  0.056002  0.576112   441.0  3232.0   
27                      -0.081235  0.114471  0.635990  2806.0  8500.0   
28                            NaN  0.119955  0.642620  2552.0  7186.0   
29                            NaN  0.084475  0.574713   254.0  1314.0   

         NPV        f1  GFP  base_rate  theil_index                   model  \
0        NaN       NaN  NaN   0.247844          NaN                    None   
1        NaN       NaN  NaN   0.312477          NaN                    None   
2        NaN       NaN  NaN   0.113576          NaN                    None   
3        NaN       NaN  NaN   0.247844          NaN                    None   
4        NaN       NaN  NaN   0.262371          NaN                    None   
5        NaN       NaN  NaN   0.158411          NaN                    None   
6        NaN       NaN  NaN   0.247730          NaN                    None   
7        NaN       NaN  NaN   0.313357          NaN                    None   
8        NaN       NaN  NaN   0.111414          NaN                    None   
9        NaN       NaN  NaN   0.247730          NaN                    None   
10       NaN       NaN  NaN   0.262472          NaN                    None   
11       NaN       NaN  NaN   0.157230          NaN                    None   
12       NaN       NaN  NaN   0.248187          NaN                    None   
13       NaN       NaN  NaN   0.309839          NaN                    None   
14       NaN       NaN  NaN   0.120065          NaN                    None   
15       NaN       NaN  NaN   0.248187          NaN                    None   
16       NaN       NaN  NaN   0.262066          NaN                    None   
17       NaN       NaN  NaN   0.161990          NaN                    None   
18  0.878000  0.664855  0.0        NaN     0.122473      logisticregression   
19  0.842962  0.674835  0.0        NaN          NaN      logisticregression   
20  0.936164  0.605898  0.0        NaN          NaN      logisticregression   
21  0.878000  0.664855  0.0        NaN     0.122473      logisticregression   
22  0.871754  0.671486  0.0        NaN          NaN      logisticregression   
23  0.912536  0.595556  0.0        NaN          NaN      logisticregression   
24  0.871887  0.620551  0.0        NaN     0.132559  decisiontreeclassifier   
25  0.830889  0.630666  0.0        NaN          NaN  decisiontreeclassifier   
26  0.939926  0.566820  0.0        NaN          NaN  decisiontreeclassifier   
27  0.871887  0.620551  0.0        NaN     0.132559  decisiontreeclassifier   
28  0.863227  0.624496  0.0        NaN          NaN  decisiontreeclassifier   
29  0.920428  0.582524  0.0        NaN          NaN  decisiontreeclassifier   

         TPR  num_positives      TP      TN     FP       FOR subset  GTNR  \
0        NaN        11208.0     NaN     NaN    NaN       NaN   full   NaN   
1        NaN         9539.0     NaN     NaN    NaN       NaN   full   NaN   
2        NaN         1669.0     NaN     NaN    NaN       NaN   full   NaN   
3        NaN        11208.0     NaN     NaN    NaN       NaN   full   NaN   
4        NaN        10207.0     NaN     NaN    NaN       NaN   full   NaN   
5        NaN         1001.0     NaN     NaN    NaN       NaN   full   NaN   
6        NaN         8402.0     NaN     NaN    NaN       NaN  train   NaN   
7        NaN         7174.0     NaN     NaN    NaN       NaN  train   NaN   
8        NaN         1228.0     NaN     NaN    NaN       NaN  train   NaN   
9        NaN         8402.0     NaN     NaN    NaN       NaN  train   NaN   
10       NaN         7655.0     NaN     NaN    NaN       NaN  train   NaN   
11       NaN          747.0     NaN     NaN    NaN       NaN  train   NaN   
12       NaN         2806.0     NaN     NaN    NaN       NaN   test   NaN   
13       NaN         2365.0     NaN     NaN    NaN       NaN   test   NaN   
14       NaN          441.0     NaN     NaN    NaN       NaN   test   NaN   
15       NaN         2806.0     NaN     NaN    NaN       NaN   test   NaN   
16       NaN         2552.0     NaN     NaN    NaN       NaN   test   NaN   
17       NaN          254.0     NaN     NaN    NaN       NaN   test   NaN   
18  0.610478            NaN  1713.0  7866.0  634.0  0.122000   test   1.0   
19  0.628753            NaN  1487.0  4713.0  555.0  0.157038   test   1.0   
20  0.512472            NaN   226.0  3153.0   79.0  0.063836   test   1.0   
21  0.610478            NaN  1713.0  7866.0  634.0  0.122000   test   1.0   
22  0.618730            NaN  1579.0  6614.0  572.0  0.128246   test   1.0   
23  0.527559            NaN   134.0  1252.0   62.0  0.087464   test   1.0   
24  0.605845            NaN  1700.0  7527.0  973.0  0.128113   test   1.0   
25  0.614799            NaN  1454.0  4476.0  792.0  0.169111   test   1.0   
26  0.557823            NaN   246.0  3051.0  181.0  0.060074   test   1.0   
27  0.605845            NaN  1700.0  7527.0  973.0  0.128113   test   1.0   
28  0.607367            NaN  1550.0  6324.0  862.0  0.136773   test   1.0   
29  0.590551            NaN   150.0  1203.0  111.0  0.079572   test   1.0   

   protected       TNR      FN privileged       FNR  accuracy  GFPR  GTPR  GFN  
0        sex       NaN     NaN       None       NaN       NaN   NaN   NaN  NaN  
1        sex       NaN     NaN       True       NaN       NaN   NaN   NaN  NaN  
2        sex       NaN     NaN      False       NaN       NaN   NaN   NaN  NaN  
3       race       NaN     NaN       None       NaN       NaN   NaN   NaN  NaN  
4       race       NaN     NaN       True       NaN       NaN   NaN   NaN  NaN  
5       race       NaN     NaN      False       NaN       NaN   NaN   NaN  NaN  
6        sex       NaN     NaN       None       NaN       NaN   NaN   NaN  NaN  
7        sex       NaN     NaN       True       NaN       NaN   NaN   NaN  NaN  
8        sex       NaN     NaN      False       NaN       NaN   NaN   NaN  NaN  
9       race       NaN     NaN       None       NaN       NaN   NaN   NaN  NaN  
10      race       NaN     NaN       True       NaN       NaN   NaN   NaN  NaN  
11      race       NaN     NaN      False       NaN       NaN   NaN   NaN  NaN  
12       sex       NaN     NaN       None       NaN       NaN   NaN   NaN  NaN  
13       sex       NaN     NaN       True       NaN       NaN   NaN   NaN  NaN  
14       sex       NaN     NaN      False       NaN       NaN   NaN   NaN  NaN  
15      race       NaN     NaN       None       NaN       NaN   NaN   NaN  NaN  
16      race       NaN     NaN       True       NaN       NaN   NaN   NaN  NaN  
17      race       NaN     NaN      False       NaN       NaN   NaN   NaN  NaN  
18       sex  0.925412  1093.0       None  0.389522  0.847249   0.0   1.0  0.0  
19       sex  0.894647   878.0       True  0.371247  0.812263   0.0   1.0  0.0  
20       sex  0.975557   215.0      False  0.487528  0.919956   0.0   1.0  0.0  
21      race  0.925412  1093.0       None  0.389522  0.847249   0.0   1.0  0.0  
22      race  0.920401   973.0       True  0.381270  0.841343   0.0   1.0  0.0  
23      race  0.952816   120.0      False  0.472441  0.883929   0.0   1.0  0.0  
24       sex  0.885529  1106.0       None  0.394155  0.816115   0.0   1.0  0.0  
25       sex  0.849658   911.0       True  0.385201  0.776890   0.0   1.0  0.0  
26       sex  0.943998   195.0      False  0.442177  0.897631   0.0   1.0  0.0  
27      race  0.885529  1106.0       None  0.394155  0.816115   0.0   1.0  0.0  
28      race  0.880045  1002.0       True  0.392633  0.808585   0.0   1.0  0.0  
29      race  0.915525   104.0      False  0.409449  0.862883   0.0   1.0  0.0  
</pre>

<div class="org-src-container">
<pre class="src src-python">adult.shape
</pre>
</div>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-right" />

<col  class="org-right" />
</colgroup>
<tbody>
<tr>
<td class="org-right">30</td>
<td class="org-right">33</td>
</tr>
</tbody>
</table>

<div class="org-src-container">
<pre class="src src-python">adult.dtypes
</pre>
</div>

<pre class="example" id="orge30a91f">
dataset                           object
GFNR                             float64
num_negatives                    float64
disparate_impact                 float64
FDR                              float64
statistical_parity_difference    float64
FPR                              float64
PPV                              float64
GTP                              float64
GTN                              float64
NPV                              float64
f1                               float64
GFP                              float64
base_rate                        float64
theil_index                      float64
model                             object
TPR                              float64
num_positives                    float64
TP                               float64
TN                               float64
FP                               float64
FOR                              float64
subset                            object
GTNR                             float64
protected                         object
TNR                              float64
FN                               float64
privileged                        object
FNR                              float64
accuracy                         float64
GFPR                             float64
GTPR                             float64
GFN                              float64
dtype: object
</pre>

<div class="org-src-container">
<pre class="src src-python">adult.describe(include='all')
</pre>
</div>

<pre class="example" id="org1813c54">
       dataset  GFNR  num_negatives  disparate_impact        FDR  \
count       30  12.0      18.000000         10.000000  12.000000   
unique       1   NaN            NaN               NaN        NaN   
top      adult   NaN            NaN               NaN        NaN   
freq        30   NaN            NaN               NaN        NaN   
mean       NaN   0.0   15117.333333          0.487087   0.328377   
std        NaN   0.0   10905.894596          0.135776   0.061294   
min        NaN   0.0    1314.000000          0.310398   0.259016   
25%        NaN   0.0    5785.000000          0.369479   0.270132   
50%        NaN   0.0   11410.000000          0.480493   0.334477   
75%        NaN   0.0   24513.000000          0.602585   0.364010   
max        NaN   0.0   34014.000000          0.672027   0.425287   

        statistical_parity_difference        FPR        PPV          GTP  \
count                       10.000000  12.000000  12.000000    12.000000   
unique                            NaN        NaN        NaN          NaN   
top                               NaN        NaN        NaN          NaN   
freq                              NaN        NaN        NaN          NaN   
mean                        -0.143950   0.087123   0.671623  1870.666667   
std                          0.050056   0.035385   0.061294  1137.448127   
min                         -0.201944   0.024443   0.574713   254.000000   
25%                         -0.188451   0.069942   0.635990   441.000000   
50%                         -0.141618   0.082037   0.665523  2458.500000   
75%                         -0.101047   0.114471   0.729868  2806.000000   
max                         -0.081235   0.150342   0.740984  2806.000000   

                GTN        NPV         f1   GFP  base_rate  theil_index model  \
count     12.000000  12.000000  12.000000  12.0  18.000000     4.000000    30   
unique          NaN        NaN        NaN   NaN        NaN          NaN     3   
top             NaN        NaN        NaN   NaN        NaN          NaN  None   
freq            NaN        NaN        NaN   NaN        NaN          NaN    18   
mean    5666.666667   0.884805   0.626925   0.0   0.224044     0.127516   NaN   
std     2808.952355   0.034947   0.036018   0.0   0.068296     0.005823   NaN   
min     1314.000000   0.830889   0.566820   0.0   0.111414     0.122473   NaN   
25%     3232.000000   0.869622   0.603312   0.0   0.159306     0.122473   NaN   
50%     6227.000000   0.874943   0.622524   0.0   0.247844     0.127516   NaN   
75%     8500.000000   0.914509   0.664855   0.0   0.262294     0.132559   NaN   
max     8500.000000   0.939926   0.674835   0.0   0.313357     0.132559   NaN   

              TPR  num_positives           TP           TN          FP  \
count   12.000000      18.000000    12.000000    12.000000   12.000000   
unique        NaN            NaN          NaN          NaN         NaN   
top           NaN            NaN          NaN          NaN         NaN   
freq          NaN            NaN          NaN          NaN         NaN   
mean     0.590892    4981.333333  1137.666667  5131.000000  535.666667   
std      0.037562    4094.371229   706.488542  2511.484132  345.725675   
min      0.512472     254.000000   134.000000  1203.000000   62.000000   
25%      0.582369    1338.250000   241.000000  3127.500000  163.500000   
50%      0.606606    2806.000000  1518.500000  5518.500000  603.000000   
75%      0.611558    8402.000000  1700.000000  7527.000000  809.500000   
max      0.628753   11208.000000  1713.000000  7866.000000  973.000000   

              FOR subset  GTNR protected        TNR           FN privileged  \
count   12.000000     30  12.0        30  12.000000    12.000000         30   
unique        NaN      3   NaN         2        NaN          NaN          3   
top           NaN   test   NaN       sex        NaN          NaN       None   
freq          NaN     18   NaN        15        NaN          NaN         10   
mean     0.115195    NaN   1.0       NaN   0.912877   733.000000        NaN   
std      0.034947    NaN   0.0       NaN   0.035385   431.625469        NaN   
min      0.060074    NaN   1.0       NaN   0.849658   104.000000        NaN   
25%      0.085491    NaN   1.0       NaN   0.885529   210.000000        NaN   
50%      0.125057    NaN   1.0       NaN   0.917963   942.000000        NaN   
75%      0.130378    NaN   1.0       NaN   0.930058  1093.000000        NaN   
max      0.169111    NaN   1.0       NaN   0.975557  1106.000000        NaN   

              FNR   accuracy  GFPR  GTPR   GFN  
count   12.000000  12.000000  12.0  12.0  12.0  
unique        NaN        NaN   NaN   NaN   NaN  
top           NaN        NaN   NaN   NaN   NaN  
freq          NaN        NaN   NaN   NaN   NaN  
mean     0.409108   0.844184   0.0   1.0   0.0  
std      0.037562   0.041500   0.0   0.0   0.0  
min      0.371247   0.776890   0.0   1.0   0.0  
25%      0.388442   0.815152   0.0   1.0   0.0  
50%      0.393394   0.844296   0.0   1.0   0.0  
75%      0.417631   0.868144   0.0   1.0   0.0  
max      0.487528   0.919956   0.0   1.0   0.0  
</pre>

<p>
Each metric is calculated for 3 different subsets of the dataset
(<code>train</code>, <code>test</code> &amp; <code>full</code>). Each metric may further be conditioned in
3 different manner as indicated by value in the <code>privileged</code> column.
<code>None</code> means the metric is calculated on the full dataset, <code>True</code>
means it is conditioned on the privileged group (ie. <code>sex</code> is 1 or
'Male' in our case) and <code>False</code> means it is conditioned on the
unprivileged group (<code>sex</code> is 0 or 'Female').
</p>
</div>
</div>

<div id="outline-container-org65b068c" class="outline-2">
<h2 id="org65b068c"><span class="section-number-2">3.</span> Analysis of protected attribute <code>sex</code></h2>
<div class="outline-text-2" id="text-3">
<p>
In this section we analyse the fairness metrics. The section is
further divided into logical subsections.
</p>

<div class="org-src-container">
<pre class="src src-python">data = adult[adult['protected'] == 'sex']
data.shape
</pre>
</div>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-right" />

<col  class="org-right" />
</colgroup>
<tbody>
<tr>
<td class="org-right">15</td>
<td class="org-right">33</td>
</tr>
</tbody>
</table>

<div class="org-src-container">
<pre class="src src-python">data
</pre>
</div>

<pre class="example" id="org1fac379">
   dataset  GFNR  num_negatives  disparate_impact       FDR  \
0    adult   NaN        34014.0          0.363470       NaN   
1    adult   NaN        20988.0               NaN       NaN   
2    adult   NaN        13026.0               NaN       NaN   
6    adult   NaN        25514.0          0.355548       NaN   
7    adult   NaN        15720.0               NaN       NaN   
8    adult   NaN         9794.0               NaN       NaN   
12   adult   NaN         8500.0          0.387509       NaN   
13   adult   NaN         5268.0               NaN       NaN   
14   adult   NaN         3232.0               NaN       NaN   
18   adult   0.0            NaN          0.310398  0.270132   
19   adult   0.0            NaN               NaN  0.271792   
20   adult   0.0            NaN               NaN  0.259016   
24   adult   0.0            NaN          0.395087  0.364010   
25   adult   0.0            NaN               NaN  0.352627   
26   adult   0.0            NaN               NaN  0.423888   

    statistical_parity_difference       FPR       PPV     GTP     GTN  \
0                       -0.198901       NaN       NaN     NaN     NaN   
1                             NaN       NaN       NaN     NaN     NaN   
2                             NaN       NaN       NaN     NaN     NaN   
6                       -0.201944       NaN       NaN     NaN     NaN   
7                             NaN       NaN       NaN     NaN     NaN   
8                             NaN       NaN       NaN     NaN     NaN   
12                      -0.189774       NaN       NaN     NaN     NaN   
13                            NaN       NaN       NaN     NaN     NaN   
14                            NaN       NaN       NaN     NaN     NaN   
18                      -0.184484  0.074588  0.729868  2806.0  8500.0   
19                            NaN  0.105353  0.728208  2365.0  5268.0   
20                            NaN  0.024443  0.740984   441.0  3232.0   
24                      -0.177995  0.114471  0.635990  2806.0  8500.0   
25                            NaN  0.150342  0.647373  2365.0  5268.0   
26                            NaN  0.056002  0.576112   441.0  3232.0   

         NPV        f1  GFP  base_rate  theil_index                   model  \
0        NaN       NaN  NaN   0.247844          NaN                    None   
1        NaN       NaN  NaN   0.312477          NaN                    None   
2        NaN       NaN  NaN   0.113576          NaN                    None   
6        NaN       NaN  NaN   0.247730          NaN                    None   
7        NaN       NaN  NaN   0.313357          NaN                    None   
8        NaN       NaN  NaN   0.111414          NaN                    None   
12       NaN       NaN  NaN   0.248187          NaN                    None   
13       NaN       NaN  NaN   0.309839          NaN                    None   
14       NaN       NaN  NaN   0.120065          NaN                    None   
18  0.878000  0.664855  0.0        NaN     0.122473      logisticregression   
19  0.842962  0.674835  0.0        NaN          NaN      logisticregression   
20  0.936164  0.605898  0.0        NaN          NaN      logisticregression   
24  0.871887  0.620551  0.0        NaN     0.132559  decisiontreeclassifier   
25  0.830889  0.630666  0.0        NaN          NaN  decisiontreeclassifier   
26  0.939926  0.566820  0.0        NaN          NaN  decisiontreeclassifier   

         TPR  num_positives      TP      TN     FP       FOR subset  GTNR  \
0        NaN        11208.0     NaN     NaN    NaN       NaN   full   NaN   
1        NaN         9539.0     NaN     NaN    NaN       NaN   full   NaN   
2        NaN         1669.0     NaN     NaN    NaN       NaN   full   NaN   
6        NaN         8402.0     NaN     NaN    NaN       NaN  train   NaN   
7        NaN         7174.0     NaN     NaN    NaN       NaN  train   NaN   
8        NaN         1228.0     NaN     NaN    NaN       NaN  train   NaN   
12       NaN         2806.0     NaN     NaN    NaN       NaN   test   NaN   
13       NaN         2365.0     NaN     NaN    NaN       NaN   test   NaN   
14       NaN          441.0     NaN     NaN    NaN       NaN   test   NaN   
18  0.610478            NaN  1713.0  7866.0  634.0  0.122000   test   1.0   
19  0.628753            NaN  1487.0  4713.0  555.0  0.157038   test   1.0   
20  0.512472            NaN   226.0  3153.0   79.0  0.063836   test   1.0   
24  0.605845            NaN  1700.0  7527.0  973.0  0.128113   test   1.0   
25  0.614799            NaN  1454.0  4476.0  792.0  0.169111   test   1.0   
26  0.557823            NaN   246.0  3051.0  181.0  0.060074   test   1.0   

   protected       TNR      FN privileged       FNR  accuracy  GFPR  GTPR  GFN  
0        sex       NaN     NaN       None       NaN       NaN   NaN   NaN  NaN  
1        sex       NaN     NaN       True       NaN       NaN   NaN   NaN  NaN  
2        sex       NaN     NaN      False       NaN       NaN   NaN   NaN  NaN  
6        sex       NaN     NaN       None       NaN       NaN   NaN   NaN  NaN  
7        sex       NaN     NaN       True       NaN       NaN   NaN   NaN  NaN  
8        sex       NaN     NaN      False       NaN       NaN   NaN   NaN  NaN  
12       sex       NaN     NaN       None       NaN       NaN   NaN   NaN  NaN  
13       sex       NaN     NaN       True       NaN       NaN   NaN   NaN  NaN  
14       sex       NaN     NaN      False       NaN       NaN   NaN   NaN  NaN  
18       sex  0.925412  1093.0       None  0.389522  0.847249   0.0   1.0  0.0  
19       sex  0.894647   878.0       True  0.371247  0.812263   0.0   1.0  0.0  
20       sex  0.975557   215.0      False  0.487528  0.919956   0.0   1.0  0.0  
24       sex  0.885529  1106.0       None  0.394155  0.816115   0.0   1.0  0.0  
25       sex  0.849658   911.0       True  0.385201  0.776890   0.0   1.0  0.0  
26       sex  0.943998   195.0      False  0.442177  0.897631   0.0   1.0  0.0  
</pre>
</div>

<div id="outline-container-org83ccc00" class="outline-3">
<h3 id="org83ccc00"><span class="section-number-3">3.1.</span> Analysis of fairness metrics</h3>
<div class="outline-text-3" id="text-3-1">
<p>
We start with the <code>num_positives</code>, <code>num_negatives</code> which are computed
only using the dataset.
</p>

<div class="org-src-container">
<pre class="src src-python">name = 'adult_barplot_prot-sex_subset-all_num-pos-neg'

fig, axs = plt.subplots(1, 2, sharey=True, figsize=(10, 5))

sns.barplot(data=data,
	    y='num_positives',
	    x='subset',
	    hue='privileged',
	    hue_order=['None', 'True', 'False'],
	    ax=axs[0])

sns.barplot(data=data,
	    y='num_negatives',
	    x='subset',
	    hue='privileged',
	    hue_order=['None', 'True', 'False'],
	    ax=axs[1])

# label the bars with the value, taken from
# &lt;https://stackoverflow.com/a/68323374&gt;
for container in axs[0].containers:
    axs[0].bar_label(container)

for container in axs[1].containers:
    axs[1].bar_label(container)

utils.savefig(fig, name)
</pre>
</div>


<div id="org58b1a03" class="figure">
<p><img src="adult_barplot_prot-sex_subset-all_num-pos-neg.png" alt="adult_barplot_prot-sex_subset-all_num-pos-neg.png" />
</p>
</div>

<p>
We note that the number of examples for the negative class is far more
than the positive class. This imbalance exists across the various
subsets, this makes sense since we take a random sample from the full
dataset to construct the train &amp; test subsets.
</p>

<p>
In both metrics, we have more examples from the privileged group. That
is, we have more examples where the sex is 'Male'.
</p>

<p>
Thus we have two separate biases that we are dealing with: first is
the imbalance in the <code>class</code> column and second is the imbalance in the
<code>sex</code> column.
</p>

<p>
Lets zoom into only the train subset. This is purely for convenience
of comparing the data &amp; model metrics together (since all model
metrics are calculated using only the test set).
</p>

<div class="org-src-container">
<pre class="src src-python">name = 'adult_barplot_prot-sex_subset-test_num-pos-neg'

fig, axs = plt.subplots(1, 2, sharey=True, figsize=(10, 5))

sns.barplot(data=data[data['subset'] == 'test'],
	    y='num_positives',
	    x='subset',
	    hue='privileged',
	    hue_order=['None', 'True', 'False'],
	    ax=axs[0])

sns.barplot(data=data[data['subset'] == 'test'],
	    y='num_negatives',
	    x='subset',
	    hue='privileged',
	    hue_order=['None', 'True', 'False'],
	    ax=axs[1])

# label the bars with the value, taken from
# &lt;https://stackoverflow.com/a/68323374&gt;
for container in axs[0].containers:
    axs[0].bar_label(container)

for container in axs[1].containers:
    axs[1].bar_label(container)

utils.savefig(fig, name)
</pre>
</div>


<div id="org545fe1f" class="figure">
<p><img src="adult_barplot_prot-sex_subset-test_num-pos-neg.png" alt="adult_barplot_prot-sex_subset-test_num-pos-neg.png" />
</p>
</div>

<p>
Lets look at the confusion matrices for the models next to understand
the biases in them. The confusion matrices come in two flavours: the
absolute &amp; normalised versions.
</p>
</div>

<div id="outline-container-orge5e8afe" class="outline-4">
<h4 id="orge5e8afe"><span class="section-number-4">3.1.1.</span> Analysis of <code>base_rate</code></h4>
<div class="outline-text-4" id="text-3-1-1">
<p>
The <code>base_rate</code> is the probability that the label of a given example
is positive.
</p>

<div class="org-src-container">
<pre class="src src-python">name = 'adult_barplot_prot-sex_base-rate'

fig, ax = plt.subplots()

sns.barplot(data=data,
	    y='base_rate',
	    x='subset',
	    hue='privileged',
	    hue_order=['None', 'True', 'False'],
	    ax=ax)

for container in ax.containers:
    ax.bar_label(container)

utils.savefig(fig, name)

</pre>
</div>


<div id="orgb6a466e" class="figure">
<p><img src="adult_barplot_prot-sex_base-rate.png" alt="adult_barplot_prot-sex_base-rate.png" />
</p>
</div>

<p>
Here, we note that the <code>base_rate</code> is similar across the subsets and
the conditions. This makes sense since we used random sampling to
generate the train &amp; test subsets.
</p>

<p>
The unconditioned <code>base_rate</code> is ~25% and this makes sense since we
have more examples of the negative class. The conditioned <code>base_rate</code>
for the privileged group is higher than the unprivileged group (~30%
vs. ~11%). This makes sense as well since we have more examples of the
privileged group.
</p>

<p>
Note that the <code>base_rate</code> can be derived mathematically using
<code>num_{positives,negatives}</code> and conditional probability.
</p>
</div>
</div>

<div id="outline-container-org6237346" class="outline-4">
<h4 id="org6237346"><span class="section-number-4">3.1.2.</span> Analysis of <code>disparate_impact</code></h4>
<div class="outline-text-4" id="text-3-1-2">
<p>
These metrics exist both for the data &amp; the model so we should compare
them and see how they differ. For each metric, we create two plots:
First, we observe the distribution of the metric across the subsets.
And second we compare the distribution of the metric when calculated
with &amp; without a model.
</p>

<p>
<code>disparate_impact</code> when calculated without a model, is expressed
mathematically as follows:
</p>

\begin{equation}
\frac{Pr(Y=1 | D = \text{unprivileged})}{Pr(Y=1 | D =
\text{privileged})}
\end{equation}

<p>
So intuitively, if we have more examples of positive class with the
privileged group (sex is 'Male'), the metric will approach 0. Ideally,
we want the metric to be high with a maximum value of 1 which
indicates that we have equal number of positive examples for both
privileged &amp; unprivileged groups. A value higher than 1 indicates that
we have more examples of unprivileged positive class in our dataset.
</p>

<div class="org-src-container">
<pre class="src src-python">name = 'adult_barplot_prot-sex_mod-none_disparate-impact'

fig, ax = plt.subplots()

sns.barplot(data=data[data['model'] == 'None'],
	    y='disparate_impact',
	    x='subset',
	    ax=ax)

for container in ax.containers:
    ax.bar_label(container)

utils.savefig(fig, name)
</pre>
</div>


<div id="org09f2fc3" class="figure">
<p><img src="adult_barplot_prot-sex_mod-none_disparate-impact.png" alt="adult_barplot_prot-sex_mod-none_disparate-impact.png" />
</p>
</div>

<p>
The <code>disparate_impact</code> across the various subsets is low. And this
makes sense since we do not have that many examples of positive class
for the unprivileged group in our dataset.
</p>

<p>
<b>Note</b> that we can calculate the disparate impact using the
 probabilities obtained from the <code>base_rate</code> figure.
</p>

<div class="org-src-container">
<pre class="src src-python">name = 'adult_barplot_prot-sex_mod-all_disparate-impact'

fig, ax = plt.subplots()

sns.barplot(data=data[data['subset'] == 'test'],
	    y='disparate_impact',
	    x='model',
	    ax=ax)

for container in ax.containers:
    ax.bar_label(container)

utils.savefig(fig, name)
</pre>
</div>


<div id="orgc8b74e1" class="figure">
<p><img src="adult_barplot_prot-sex_mod-all_disparate-impact.png" alt="adult_barplot_prot-sex_mod-all_disparate-impact.png" />
</p>
</div>

<p>
When we calculate <code>disparate_impact</code> using a model, we use the
predictions instead of the actual label. The mathematical formula
changes to the following.
</p>

\begin{equation}
\frac{Pr(\hat{Y}=1 | D = \text{unprivileged})}{Pr(\hat{Y}=1 | D =
\text{privileged})}
\end{equation}

<p>
The <code>disparate_impact</code> in the model is similar to what we see in the
dataset. This makes sense since the model merely reflects the
statistics of the dataset.
</p>

<p>
The <code>disparate_impact</code> in the decisiontreeclassifier is slightly
higher than the rest. This indicates that the model is "learning"
something different &amp; is able to account for the bias in the dataset.
Perhaps with more tuning this score can be improved?
</p>
</div>
</div>

<div id="outline-container-orgb2d1f4f" class="outline-4">
<h4 id="orgb2d1f4f"><span class="section-number-4">3.1.3.</span> Analysis of <code>statistical_parity_difference</code></h4>
<div class="outline-text-4" id="text-3-1-3">
<p>
The <code>statistical_parity_difference</code> is expressed mathematically as
follows.
</p>

\begin{equation}
Pr(Y=1 | D = \text{unprivileged}) - Pr(Y=1 | D = \text{privileged})
\end{equation}

<p>
Intuitively, the value for this metric falls within the range of \([-1,
1]\). A value of 0 indicates that the dataset contains equal number of
positive examples for both privileged &amp; unprivileged groups. A value
of -1 is not ideal since it indicates that the dataset contains
significantly more examples of the positive class with the privileged
group. The idea value for this metric thus lies between \([0, 1]\).
</p>

<div class="org-src-container">
<pre class="src src-python">name = 'adult_barplot_prot-sex_mod-none_stat-par-diff'

fig, ax = plt.subplots()

sns.barplot(data=data[data['model'] == 'None'],
	    y='statistical_parity_difference',
	    x='subset',
	    ax=ax)

for container in ax.containers:
    ax.bar_label(container)

utils.savefig(fig, name)
</pre>
</div>


<div id="org3a16c74" class="figure">
<p><img src="adult_barplot_prot-sex_mod-none_stat-par-diff.png" alt="adult_barplot_prot-sex_mod-none_stat-par-diff.png" />
</p>
</div>

<div class="org-src-container">
<pre class="src src-python">name = 'adult_barplot_prot-sex_mod-all_stat-par-diff'

fig, ax = plt.subplots()

sns.barplot(data=data[data['subset'] == 'test'],
	    y='statistical_parity_difference',
	    x='model',
	    ax=ax)

for container in ax.containers:
    ax.bar_label(container)

utils.savefig(fig, name)
</pre>
</div>


<div id="orgf812292" class="figure">
<p><img src="adult_barplot_prot-sex_mod-all_stat-par-diff.png" alt="adult_barplot_prot-sex_mod-all_stat-par-diff.png" />
</p>
</div>

<p>
Again, the metric is negative both in the data &amp; model since we have
more examples of the positive class with the privileged group.
</p>

<p>
Again, we see that decisiontreeclassifier performs better than others.
</p>

<p>
<b>Main takeaway</b> here is that we can explain &amp; derive the above metrics
using statistics from the data. However, when using a model, the
numbers deviate from those calculated using just the data. This is
expected since the models introduce non-linearity into the mix.
</p>

<p>
Thus, we can use the data-centric metrics to give us an indication of
what the model-centric metrics may look like. But we need to train,
test &amp; analyse the model predictions to be sure. This is the first
point of divergence where we can no longer explain the model metrics
using the data metrics.
</p>
</div>
</div>
</div>

<div id="outline-container-org7608f04" class="outline-3">
<h3 id="org7608f04"><span class="section-number-3">3.2.</span> Analysis of performance metrics</h3>
<div class="outline-text-3" id="text-3-2">
<p>
The wikipedia page on <a href="https://en.wikipedia.org/wiki/Binary_classification">binary classification</a> was very helpful to make
sense of these metrics. Following is a table summarising their
mathematical formulas
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">metric</th>
<th scope="col" class="org-left">formula</th>
<th scope="col" class="org-left">alias</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">TPR</td>
<td class="org-left">TP/P OR TP/(TP+FN)</td>
<td class="org-left">recall/sensitivity</td>
</tr>

<tr>
<td class="org-left">FPR</td>
<td class="org-left">FP/N</td>
<td class="org-left">1 - TNR</td>
</tr>

<tr>
<td class="org-left">FNR</td>
<td class="org-left">FN/P</td>
<td class="org-left">1 - TPR</td>
</tr>

<tr>
<td class="org-left">TNR</td>
<td class="org-left">TN/N</td>
<td class="org-left">specificity</td>
</tr>

<tr>
<td class="org-left">PPV</td>
<td class="org-left">TP/(TP+FP)</td>
<td class="org-left">precision</td>
</tr>

<tr>
<td class="org-left">FDR</td>
<td class="org-left">FP/(TP+FP)</td>
<td class="org-left">1 - PPV</td>
</tr>

<tr>
<td class="org-left">FOR</td>
<td class="org-left">FN/(TN+FN)</td>
<td class="org-left">1 - NPV</td>
</tr>

<tr>
<td class="org-left">NPV</td>
<td class="org-left">TN/(TN+FN)</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-left">accuracy</td>
<td class="org-left">(TP+TN)/P+N</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-left">f1</td>
<td class="org-left">(2*precision*recall)/precision+recall</td>
<td class="org-left">&#xa0;</td>
</tr>
</tbody>
</table>

<p>
Following is a model of the binary confusion matrix.
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-right" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<tbody>
<tr>
<td class="org-left">y<sub>true</sub></td>
<td class="org-right">0</td>
<td class="org-left">TN</td>
<td class="org-left">FP</td>
</tr>

<tr>
<td class="org-left">y<sub>true</sub></td>
<td class="org-right">1</td>
<td class="org-left">FN</td>
<td class="org-left">TP</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-right">&#xa0;</td>
<td class="org-left">0</td>
<td class="org-left">1</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-right">&#xa0;</td>
<td class="org-left">y<sub>pred</sub></td>
<td class="org-left">y<sub>pred</sub></td>
</tr>
</tbody>
</table>

<p>
We focus on a subset of the metrics above. The following are the
metrics we focus on along with a short description &amp; interpretation of
the metric.
</p>

<dl class="org-dl">
<dt>Accuracy</dt><dd>The accuracy determines the correctness of the model's
predictions. Although, with an imbalanced dataset, this metric can
be misleading.</dd>
<dt>Precision</dt><dd>The correctness of the model in predicting the positive
class out of all positive class predictions. In other words, the
precision is the accuracy of the negative class.</dd>
<dt>Recall</dt><dd>The recall provides an indication of the missed positive
predictions.</dd>
<dt>f1</dt><dd>Harmonic mean of precision &amp; recall. It combines the two
metrics into a single one.</dd>
</dl>

<p>
The section is further divided based on the model. For each model, we
analyse the confusion matrices and the performance metrics.
</p>
</div>

<div id="outline-container-org5f1bd6d" class="outline-4">
<h4 id="org5f1bd6d"><span class="section-number-4">3.2.1.</span> model: logisticregression</h4>
<div class="outline-text-4" id="text-3-2-1">
<div class="org-src-container">
<pre class="src src-python">name = 'adult_heatmap_prot-sex_mod-lr_cm'
metrics = data[data['model'] == 'logisticregression']
cols = ['TN', 'FP', 'FN', 'TP']
fig, axs = plt.subplots(1, 3, figsize=(15, 5))

for idx, privileged in enumerate(['None', 'True', 'False']):
    cm = metrics[metrics['privileged'] == privileged]
    cm = cm[cols].values.reshape(2,2)
    sns.heatmap(data=cm,
		annot=cm,
		fmt="",
		cbar=False,
		cmap='Blues',
		ax=axs[idx])
    axs[idx].set_xlabel("y_pred")
    axs[idx].set_ylabel("y_true")
    axs[idx].set_title(privileged)

utils.savefig(fig, name)
</pre>
</div>


<div id="orgda997ed" class="figure">
<p><img src="adult_heatmap_prot-sex_mod-lr_cm.png" alt="adult_heatmap_prot-sex_mod-lr_cm.png" />
</p>
</div>

<div class="org-src-container">
<pre class="src src-python">name = 'adult_heatmap_prot-sex_mod-lr_cm-rate'
metrics = data[data['model'] == 'logisticregression']
cols = ['TNR', 'FPR', 'FNR', 'TPR']
fig, axs = plt.subplots(1, 3, figsize=(15, 5))

for idx, privileged in enumerate(['None', 'True', 'False']):
    cm = metrics[metrics['privileged'] == privileged]
    cm = cm[cols].values.reshape(2,2)
    sns.heatmap(data=cm,
		annot=cm,
		fmt=".3f",
		cbar=False,
		cmap='Blues',
		ax=axs[idx])
    axs[idx].set_xlabel("y_pred")
    axs[idx].set_ylabel("y_true")
    axs[idx].set_title(privileged)

utils.savefig(fig, name)
</pre>
</div>


<div id="org4a72e2c" class="figure">
<p><img src="adult_heatmap_prot-sex_mod-lr_cm-rate.png" alt="adult_heatmap_prot-sex_mod-lr_cm-rate.png" />
</p>
</div>

<p>
The model does well with the negative class (~92% accuracy). It
doesn't do so well with the positive class (~61% accuracy) with a less
then idea false negative rate (~39%). This is expected since we have
more number of negative examples in the dataset.
</p>

<p>
The performance of the model remains some what similar across the
conditions on the protected attribute.
</p>

<p>
There is a slight uptick in the true negative rate when we condition
on the unprivileged group (right more plot). The true positive rate
drops slightly here as well, with a rise in the false positive rate.
So the model is able to classify women with a lower income with high
accuracy. But the performance is 50-50 when it comes to women with a
higher income. And this again is corroborated by the fact that we
trained the model with very few examples of women with a high income.
</p>

<div class="org-src-container">
<pre class="src src-python">name = 'adult_barplot_prot-sex_mod-lr_acc-pre-rec-f1'
metrics = data[data['model'] == 'logisticregression']
hue_order = ['None', 'True', 'False']

fig, axs = plt.subplots(1, 4, sharey=True, figsize=(20, 5))

sns.barplot(data=metrics,
	    y='accuracy',
	    x='subset',
	    hue='privileged',
	    hue_order=hue_order,
	    ax=axs[0])

sns.barplot(data=metrics,
	    y='PPV',
	    x='subset',
	    hue='privileged',
	    hue_order=hue_order,
	    ax=axs[1])
axs[1].set_ylabel('precision')

sns.barplot(data=metrics,
	    y='TPR',
	    x='subset',
	    hue='privileged',
	    hue_order=hue_order,
	    ax=axs[2])
axs[2].set_ylabel('recall')

sns.barplot(data=metrics,
	    y='f1',
	    x='subset',
	    hue='privileged',
	    hue_order=hue_order,
	    ax=axs[3])

for idx in range(4):
    for container in axs[idx].containers: axs[idx].bar_label(container)

utils.savefig(fig, name)
</pre>
</div>


<div id="org46e3cd3" class="figure">
<p><img src="adult_barplot_prot-sex_mod-lr_acc-pre-rec-f1.png" alt="adult_barplot_prot-sex_mod-lr_acc-pre-rec-f1.png" />
</p>
</div>

<p>
The accuracy of the model is high however the dataset is skewed so we
should focus on the precision &amp; recall instead.
</p>

<p>
The precision is higher than the recall since \((TP+FP) < (TP+FN)\). And
we have more FN since we trained with a dataset with more number of
negative examples.
</p>
</div>
</div>

<div id="outline-container-org2da597d" class="outline-4">
<h4 id="org2da597d"><span class="section-number-4">3.2.2.</span> model: decisiontreeclassifier</h4>
<div class="outline-text-4" id="text-3-2-2">
<div class="org-src-container">
<pre class="src src-python">name = 'adult_heatmap_prot-sex_mod-dt_cm'
metrics = data[data['model'] == 'decisiontreeclassifier']
cols = ['TN', 'FP', 'FN', 'TP']
fig, axs = plt.subplots(1, 3, figsize=(15, 5))

for idx, privileged in enumerate(['None', 'True', 'False']):
    cm = metrics[metrics['privileged'] == privileged]
    cm = cm[cols].values.reshape(2,2)
    sns.heatmap(data=cm,
		annot=cm,
		fmt="",
		cbar=False,
		cmap='Blues',
		ax=axs[idx])
    axs[idx].set_xlabel("y_pred")
    axs[idx].set_ylabel("y_true")
    axs[idx].set_title(privileged)

utils.savefig(fig, name)
</pre>
</div>


<div id="org0f504ae" class="figure">
<p><img src="adult_heatmap_prot-sex_mod-dt_cm.png" alt="adult_heatmap_prot-sex_mod-dt_cm.png" />
</p>
</div>

<div class="org-src-container">
<pre class="src src-python">name = 'adult_heatmap_prot-sex_mod-dt_cm-rate'
metrics = data[data['model'] == 'decisiontreeclassifier']
cols = ['TNR', 'FPR', 'FNR', 'TPR']
fig, axs = plt.subplots(1, 3, figsize=(15, 5))

for idx, privileged in enumerate(['None', 'True', 'False']):
    cm = metrics[metrics['privileged'] == privileged]
    cm = cm[cols].values.reshape(2,2)
    sns.heatmap(data=cm,
		annot=cm,
		fmt=".3f",
		cbar=False,
		cmap='Blues',
		ax=axs[idx])
    axs[idx].set_xlabel("y_pred")
    axs[idx].set_ylabel("y_true")
    axs[idx].set_title(privileged)

utils.savefig(fig, name)
</pre>
</div>


<div id="org68aa977" class="figure">
<p><img src="adult_heatmap_prot-sex_mod-dt_cm-rate.png" alt="adult_heatmap_prot-sex_mod-dt_cm-rate.png" />
</p>
</div>

<p>
The general trend is the same across both models: they are able to
detect the negative class well but fail to do so for the positive
class.
</p>

<p>
Compared to logisticregression, the decisiontreeclassifier performs
slightly worse. However, we must account for the fact that the model
is not tuned. The performance many increase with some effort invested
in model tuning.
</p>

<div class="org-src-container">
<pre class="src src-python">name = 'adult_barplot_prot-sex_mod-dt_acc-pre-rec-f1'
metrics = data[data['model'] == 'decisiontreeclassifier']
hue_order = ['None', 'True', 'False']

fig, axs = plt.subplots(1, 4, sharey=True, figsize=(20, 5))

sns.barplot(data=metrics,
	    y='accuracy',
	    x='subset',
	    hue='privileged',
	    hue_order=hue_order,
	    ax=axs[0])

sns.barplot(data=metrics,
	    y='PPV',
	    x='subset',
	    hue='privileged',
	    hue_order=hue_order,
	    ax=axs[1])
axs[1].set_ylabel('precision')

sns.barplot(data=metrics,
	    y='TPR',
	    x='subset',
	    hue='privileged',
	    hue_order=hue_order,
	    ax=axs[2])
axs[2].set_ylabel('recall')

sns.barplot(data=metrics,
	    y='f1',
	    x='subset',
	    hue='privileged',
	    hue_order=hue_order,
	    ax=axs[3])

for idx in range(4):
    for container in axs[idx].containers: axs[idx].bar_label(container)

utils.savefig(fig, name)
</pre>
</div>


<div id="orgccb6c66" class="figure">
<p><img src="adult_barplot_prot-sex_mod-dt_acc-pre-rec-f1.png" alt="adult_barplot_prot-sex_mod-dt_acc-pre-rec-f1.png" />
</p>
</div>

<p>
Similar results; similar reasons.
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-orgb7c290f" class="outline-2">
<h2 id="orgb7c290f"><span class="section-number-2">4.</span> Analysis of protected attribute <code>race</code></h2>
<div class="outline-text-2" id="text-4">
<p>
In this section we expand &amp; compare the metrics for both the race
attribute.
</p>

<div class="org-src-container">
<pre class="src src-python">data = adult[adult['protected'] == 'race']
data.shape
</pre>
</div>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-right" />

<col  class="org-right" />
</colgroup>
<tbody>
<tr>
<td class="org-right">15</td>
<td class="org-right">33</td>
</tr>
</tbody>
</table>
</div>

<div id="outline-container-orged13339" class="outline-3">
<h3 id="orged13339"><span class="section-number-3">4.1.</span> Analysis of fairness metrics</h3>
<div class="outline-text-3" id="text-4-1">
<div class="org-src-container">
<pre class="src src-python">name = 'adult_barplot_prot-race_subset-all_num-pos-neg'

fig, axs = plt.subplots(1, 2, sharey=True, figsize=(10, 5))

sns.barplot(data=data,
	    y='num_positives',
	    x='subset',
	    hue='privileged',
	    hue_order=['None', 'True', 'False'],
	    ax=axs[0])

for container in axs[0].containers:
    axs[0].bar_label(container)

sns.barplot(data=data,
	    y='num_negatives',
	    x='subset',
	    hue='privileged',
	    hue_order=['None', 'True', 'False'],
	    ax=axs[1])

for container in axs[1].containers:
    axs[1].bar_label(container)

utils.savefig(fig, name)
</pre>
</div>


<div id="orgac044a4" class="figure">
<p><img src="adult_barplot_prot-race_subset-all_num-pos-neg.png" alt="adult_barplot_prot-race_subset-all_num-pos-neg.png" />
</p>
</div>

<p>
The imbalance between the positive &amp; negative classes remains for this
protected attribute as well (which is expected). As with sex, we have
more examples of the privileged group for both positive &amp; negative
class.
</p>

<div class="org-src-container">
<pre class="src src-python">name = 'adult_barplot_prot-race_subset-test_num-pos-neg'

fig, axs = plt.subplots(1, 2, sharey=True, figsize=(10, 5))

sns.barplot(data=data[data['subset'] == 'test'],
	    y='num_positives',
	    x='subset',
	    hue='privileged',
	    hue_order=['None', 'True', 'False'],
	    ax=axs[0])

for container in axs[0].containers:
    axs[0].bar_label(container)

sns.barplot(data=data[data['subset'] == 'test'],
	    y='num_negatives',
	    x='subset',
	    hue='privileged',
	    hue_order=['None', 'True', 'False'],
	    ax=axs[1])

for container in axs[1].containers:
    axs[1].bar_label(container)

utils.savefig(fig, name)
</pre>
</div>


<div id="org2ec7acb" class="figure">
<p><img src="adult_barplot_prot-race_subset-test_num-pos-neg.png" alt="adult_barplot_prot-race_subset-test_num-pos-neg.png" />
</p>
</div>
</div>

<div id="outline-container-org2fd084b" class="outline-4">
<h4 id="org2fd084b"><span class="section-number-4">4.1.1.</span> Analysis of <code>base_rate</code></h4>
<div class="outline-text-4" id="text-4-1-1">
<div class="org-src-container">
<pre class="src src-python">name = 'adult_barplot_prot-race_base-rate'

fig, ax = plt.subplots()

sns.barplot(data=data,
	    y='base_rate',
	    x='subset',
	    hue='privileged',
	    hue_order=['None', 'True', 'False'],
	    ax=ax)

for container in ax.containers:
    ax.bar_label(container)

utils.savefig(fig, name)

</pre>
</div>


<div id="orgb8c0d9a" class="figure">
<p><img src="adult_barplot_prot-race_base-rate.png" alt="adult_barplot_prot-race_base-rate.png" />
</p>
</div>

<p>
The base rate is similar across all subsets since we derive the
training &amp; testing set by random sampling of the entire dataset. The
base rate conditioned on the privileged group is higher than the the
unprivileged group and this too is reflected in the training data.
</p>
</div>
</div>

<div id="outline-container-orgd1a508f" class="outline-4">
<h4 id="orgd1a508f"><span class="section-number-4">4.1.2.</span> Analysis of <code>disparate_impact</code></h4>
<div class="outline-text-4" id="text-4-1-2">
<div class="org-src-container">
<pre class="src src-python">name = 'adult_barplot_prot-race_mod-none_disparate-impact'

fig, ax = plt.subplots()

sns.barplot(data=data[data['model'] == 'None'],
	    y='disparate_impact',
	    x='subset',
	    ax=ax)

for container in ax.containers:
    ax.bar_label(container)

utils.savefig(fig, name)
</pre>
</div>


<div id="orga73d1ac" class="figure">
<p><img src="adult_barplot_prot-race_mod-none_disparate-impact.png" alt="adult_barplot_prot-race_mod-none_disparate-impact.png" />
</p>
</div>

<div class="org-src-container">
<pre class="src src-python">name = 'adult_barplot_prot-race_mod-all_disparate-impact'

fig, ax = plt.subplots()

sns.barplot(data=data[data['subset'] == 'test'],
	    y='disparate_impact',
	    x='model',
	    ax=ax)

for container in ax.containers:
    ax.bar_label(container)

utils.savefig(fig, name)
</pre>
</div>


<div id="orgbf0346f" class="figure">
<p><img src="adult_barplot_prot-race_mod-all_disparate-impact.png" alt="adult_barplot_prot-race_mod-all_disparate-impact.png" />
</p>
</div>

<p>
The <code>disparate_impact</code> in the model is similar to that observed in the
dataset.
</p>

<p>
The <code>disparate_impact</code> for race attribute is higher compared to that
observed in sex. This can be explained by taking a closer look at the
mathematical formulas. Lets take a closer look.
</p>

\begin{equation}
\text{disparate impact} = \frac{P(Y=1 | D=\text{unprivileged})}{P(Y=1 | D=\text{privileged})}
\end{equation}

\begin{equation}
P(Y=1 | D=\text{privileged}) = \frac{P(Y=1 \cap D=\text{privileged})}{P(D=\text{privileged})}
\end{equation}

\begin{equation}
P(D=\text{privileged}) = \frac{\text{number of privileged examples}}{\text{total number of examples}}
\end{equation}

\begin{equation}
\text{number of privileged examples} \propto P(D=\text{privileged}) \propto \frac{1}{P(Y=1 | D=\text{privileged})} \propto \frac{1}{\text{disparate impact}}
\end{equation}

<p>
Thus, a higher number of privileged group examples (which is the case
for the race attribute), results in a higher <code>disparate_impact</code>.
</p>
</div>
</div>

<div id="outline-container-orgeb3aea7" class="outline-4">
<h4 id="orgeb3aea7"><span class="section-number-4">4.1.3.</span> Analysis of <code>statistical_parity_difference</code></h4>
<div class="outline-text-4" id="text-4-1-3">
<div class="org-src-container">
<pre class="src src-python">name = 'adult_barplot_prot-race_mod-none_stat-par-diff'

fig, ax = plt.subplots()

sns.barplot(data=data[data['model'] == 'None'],
	    y='statistical_parity_difference',
	    x='subset',
	    ax=ax)

for container in ax.containers:
    ax.bar_label(container)

utils.savefig(fig, name)
</pre>
</div>


<div id="org8f73c1d" class="figure">
<p><img src="adult_barplot_prot-race_mod-none_stat-par-diff.png" alt="adult_barplot_prot-race_mod-none_stat-par-diff.png" />
</p>
</div>

<div class="org-src-container">
<pre class="src src-python">name = 'adult_barplot_prot-race_mod-all_stat-par-diff'

fig, ax = plt.subplots()

sns.barplot(data=data[data['subset'] == 'test'],
	    y='statistical_parity_difference',
	    x='model',
	    ax=ax)

for container in ax.containers:
    ax.bar_label(container)

utils.savefig(fig, name)
</pre>
</div>


<div id="orgc19987d" class="figure">
<p><img src="adult_barplot_prot-race_mod-all_stat-par-diff.png" alt="adult_barplot_prot-race_mod-all_stat-par-diff.png" />
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-org44a8b1e" class="outline-3">
<h3 id="org44a8b1e"><span class="section-number-3">4.2.</span> Analysis of performance metrics</h3>
<div class="outline-text-3" id="text-4-2">
</div>
<div id="outline-container-org85c9996" class="outline-4">
<h4 id="org85c9996"><span class="section-number-4">4.2.1.</span> model: logisticregression</h4>
<div class="outline-text-4" id="text-4-2-1">
<div class="org-src-container">
<pre class="src src-python">name = 'adult_heatmap_prot-race_mod-lr_cm'
metrics = data[data['model'] == 'logisticregression']
cols = ['TN', 'FP', 'FN', 'TP']
fig, axs = plt.subplots(1, 3, figsize=(15, 5))

for idx, privileged in enumerate(['None', 'True', 'False']):
    cm = metrics[metrics['privileged'] == privileged]
    cm = cm[cols].values.reshape(2,2)
    sns.heatmap(data=cm,
		annot=cm,
		fmt="",
		cbar=False,
		cmap='Blues',
		ax=axs[idx])
    axs[idx].set_xlabel("y_pred")
    axs[idx].set_ylabel("y_true")
    axs[idx].set_title(privileged)

utils.savefig(fig, name)
</pre>
</div>


<div id="orge552db6" class="figure">
<p><img src="adult_heatmap_prot-race_mod-lr_cm.png" alt="adult_heatmap_prot-race_mod-lr_cm.png" />
</p>
</div>

<div class="org-src-container">
<pre class="src src-python">name = 'adult_heatmap_prot-race_mod-lr_cm-rate'
metrics = data[data['model'] == 'logisticregression']
cols = ['TNR', 'FPR', 'FNR', 'TPR']
fig, axs = plt.subplots(1, 3, figsize=(15, 5))

for idx, privileged in enumerate(['None', 'True', 'False']):
    cm = metrics[metrics['privileged'] == privileged]
    cm = cm[cols].values.reshape(2,2)
    sns.heatmap(data=cm,
		annot=cm,
		fmt=".3f",
		cbar=False,
		cmap='Blues',
		ax=axs[idx])
    axs[idx].set_xlabel("y_pred")
    axs[idx].set_ylabel("y_true")
    axs[idx].set_title(privileged)

utils.savefig(fig, name)
</pre>
</div>


<div id="org0441bc8" class="figure">
<p><img src="adult_heatmap_prot-race_mod-lr_cm-rate.png" alt="adult_heatmap_prot-race_mod-lr_cm-rate.png" />
</p>
</div>

<p>
As with sex, the model performs well with the negative class. This is
expected since the training set contains more examples of the negative
class.
</p>

<p>
The performance of the model for the negative class is consistent
across the conditions. The performance for the unprivileged positive
class is worse than the privileged positive class. This makes sense
since we have more examples of privileged positive class in our
training dataset.
</p>

<div class="org-src-container">
<pre class="src src-python">name = 'adult_barplot_prot-race_mod-lr_acc-pre-rec-f1'
metrics = data[data['model'] == 'logisticregression']
hue_order = ['None', 'True', 'False']

fig, axs = plt.subplots(1, 4, sharey=True, figsize=(20, 5))

sns.barplot(data=metrics,
	    y='accuracy',
	    x='subset',
	    hue='privileged',
	    hue_order=hue_order,
	    ax=axs[0])

sns.barplot(data=metrics,
	    y='PPV',
	    x='subset',
	    hue='privileged',
	    hue_order=hue_order,
	    ax=axs[1])
axs[1].set_ylabel('precision')

sns.barplot(data=metrics,
	    y='TPR',
	    x='subset',
	    hue='privileged',
	    hue_order=hue_order,
	    ax=axs[2])
axs[2].set_ylabel('recall')

sns.barplot(data=metrics,
	    y='f1',
	    x='subset',
	    hue='privileged',
	    hue_order=hue_order,
	    ax=axs[3])

for idx in range(4):
    for container in axs[idx].containers: axs[idx].bar_label(container)

utils.savefig(fig, name)
</pre>
</div>


<div id="org1277a08" class="figure">
<p><img src="adult_barplot_prot-race_mod-lr_acc-pre-rec-f1.png" alt="adult_barplot_prot-race_mod-lr_acc-pre-rec-f1.png" />
</p>
</div>

<p>
The results are similar to that of sex attribute (the numbers are
similar as well), precision is higher than recall since the sum
\((TP+FP)\) is lower than \((TP+FN)\).
</p>


<div id="org54c7951" class="figure">
<p><img src="adult_barplot_prot-race_mod-lr_acc-pre-rec-f1.png" alt="adult_barplot_prot-race_mod-lr_acc-pre-rec-f1.png" />
</p>
</div>
</div>
</div>

<div id="outline-container-orgde804fc" class="outline-4">
<h4 id="orgde804fc"><span class="section-number-4">4.2.2.</span> model: decisiontreeclassifier</h4>
<div class="outline-text-4" id="text-4-2-2">
<div class="org-src-container">
<pre class="src src-python">name = 'adult_heatmap_prot-race_mod-dt_cm'
metrics = data[data['model'] == 'decisiontreeclassifier']
cols = ['TN', 'FP', 'FN', 'TP']
fig, axs = plt.subplots(1, 3, figsize=(15, 5))

for idx, privileged in enumerate(['None', 'True', 'False']):
    cm = metrics[metrics['privileged'] == privileged]
    cm = cm[cols].values.reshape(2,2)
    sns.heatmap(data=cm,
		annot=cm,
		fmt="",
		cbar=False,
		cmap='Blues',
		ax=axs[idx])
    axs[idx].set_xlabel("y_pred")
    axs[idx].set_ylabel("y_true")
    axs[idx].set_title(privileged)

utils.savefig(fig, name)
</pre>
</div>


<div id="orge0716ff" class="figure">
<p><img src="adult_heatmap_prot-race_mod-dt_cm.png" alt="adult_heatmap_prot-race_mod-dt_cm.png" />
</p>
</div>

<div class="org-src-container">
<pre class="src src-python">name = 'adult_heatmap_prot-race_mod-dt_cm-rate'
metrics = data[data['model'] == 'decisiontreeclassifier']
cols = ['TNR', 'FPR', 'FNR', 'TPR']
fig, axs = plt.subplots(1, 3, figsize=(15, 5))

for idx, privileged in enumerate(['None', 'True', 'False']):
    cm = metrics[metrics['privileged'] == privileged]
    cm = cm[cols].values.reshape(2,2)
    sns.heatmap(data=cm,
		annot=cm,
		fmt=".3f",
		cbar=False,
		cmap='Blues',
		ax=axs[idx])
    axs[idx].set_xlabel("y_pred")
    axs[idx].set_ylabel("y_true")
    axs[idx].set_title(privileged)

utils.savefig(fig, name)
</pre>
</div>


<div id="org9842d96" class="figure">
<p><img src="adult_heatmap_prot-race_mod-dt_cm-rate.png" alt="adult_heatmap_prot-race_mod-dt_cm-rate.png" />
</p>
</div>

<p>
Both models are able to detect the negative class better than the
positive class. There is a slight performance decrease in the
decisiontreeclassifier compared to the logisticregression, however
keep in mind that we did not tune the model.
</p>

<div class="org-src-container">
<pre class="src src-python">name = 'adult_barplot_prot-race_mod-dt_acc-pre-rec-f1'
metrics = data[data['model'] == 'decisiontreeclassifier']
hue_order = ['None', 'True', 'False']

fig, axs = plt.subplots(1, 4, sharey=True, figsize=(20, 5))

sns.barplot(data=metrics,
	    y='accuracy',
	    x='subset',
	    hue='privileged',
	    hue_order=hue_order,
	    ax=axs[0])

sns.barplot(data=metrics,
	    y='PPV',
	    x='subset',
	    hue='privileged',
	    hue_order=hue_order,
	    ax=axs[1])
axs[1].set_ylabel('precision')

sns.barplot(data=metrics,
	    y='TPR',
	    x='subset',
	    hue='privileged',
	    hue_order=hue_order,
	    ax=axs[2])
axs[2].set_ylabel('recall')

sns.barplot(data=metrics,
	    y='f1',
	    x='subset',
	    hue='privileged',
	    hue_order=hue_order,
	    ax=axs[3])

for idx in range(4):
    for container in axs[idx].containers: axs[idx].bar_label(container)

utils.savefig(fig, name)
</pre>
</div>


<div id="org1022152" class="figure">
<p><img src="adult_barplot_prot-race_mod-dt_acc-pre-rec-f1.png" alt="adult_barplot_prot-race_mod-dt_acc-pre-rec-f1.png" />
</p>
</div>

<p>
Results are similar to logisticregression although the difference
between precision &amp; recall is lower.
</p>

<p>
Results are similar to decisiontreeclassifier for the sex attribute.
</p>


<div id="orge37c2ef" class="figure">
<p><img src="adult_barplot_prot-race_mod-dt_acc-pre-rec-f1.png" alt="adult_barplot_prot-race_mod-dt_acc-pre-rec-f1.png" />
</p>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="date">Date: 2022-07-25 Mon 00:00</p>
<p class="author">Author: Arumoy Shome</p>
<p class="date">Created: 2022-08-24 Wed 16:38</p>
</div>
</body>
</html>
