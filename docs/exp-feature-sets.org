#+title: Experiment with Feature Sets
#+date: [2022-10-17 Mon]
#+options: toc:t
#+toc: tables
#+html_head: <link rel="stylesheet" href="main.css">
#+property: header-args:python :session *sh22qual* :exports both :eval no-export

This document analyses the =data/exp-feature-sets-*-50.csv= datasets
ie. results from the feature sets experiments.

* Init

#+begin_src python :results silent
  import os
  import sys
  import pandas as pd
  import numpy as np
  import seaborn as sns
  import matplotlib.pyplot as plt

  ROOTDIR = os.path.abspath(os.path.join(os.getcwd(), ".."))
  DATADIR = os.path.join(ROOTDIR, "data")
  sys.path.insert(0, ROOTDIR)
  pd.set_option('display.max_columns', None)
  pd.set_option('display.max_colwidth', None)
#+end_src

* EDA
Lets analyse the data obtained from 50 iterations of the experiment.
First, we need to combine the datasets into a single dataframe.

#+begin_src python
  data = pd.read_csv(os.path.join(DATADIR, "exp-feature-sets-adult-sex-50.csv"))

  data
#+end_src

#+RESULTS:
#+begin_example
      theil_index  base_rate       PPV  num_negatives dataset_label       FPR  \
0             NaN   0.245356       NaN         8532.0         adult       NaN   
1             NaN   0.248673       NaN        25482.0         adult       NaN   
2             NaN   0.311000       NaN         5224.0         adult       NaN   
3             NaN   0.312966       NaN        15764.0         adult       NaN   
4             NaN   0.111708       NaN         3308.0         adult       NaN   
...           ...        ...       ...            ...           ...       ...   
8095          NaN        NaN  0.689952            NaN         adult  0.123877   
8096          NaN        NaN  0.713208            NaN         adult  0.023544   
8097     0.145611        NaN  0.620676            NaN         adult  0.116680   
8098          NaN        NaN  0.626452            NaN         adult  0.159816   
8099          NaN        NaN  0.563025            NaN         adult  0.048327   

           TPR      FN privileged  num_positives       FNR      TP protected  \
0          NaN     NaN       None         2774.0       NaN     NaN       sex   
1          NaN     NaN       None         8434.0       NaN     NaN       sex   
2          NaN     NaN       True         2358.0       NaN     NaN       sex   
3          NaN     NaN       True         7181.0       NaN     NaN       sex   
4          NaN     NaN      False          416.0       NaN     NaN       sex   
...        ...     ...        ...            ...       ...     ...       ...   
8095  0.598340   968.0       True            NaN  0.401660  1442.0       sex   
8096  0.432494   248.0      False            NaN  0.567506   189.0       sex   
8097  0.567264  1232.0       None            NaN  0.432736  1615.0       sex   
8098  0.581743  1008.0       True            NaN  0.418257  1402.0       sex   
8099  0.459954   236.0      False            NaN  0.540046   201.0       sex   

      iteration      TN       TNR                   model  \
0             0     NaN       NaN                    None   
1             0     NaN       NaN                    None   
2             0     NaN       NaN                    None   
3             0     NaN       NaN                    None   
4             0     NaN       NaN                    None   
...         ...     ...       ...                     ...   
8095         49  4583.0  0.876123      adaboostclassifier   
8096         49  3152.0  0.976456      adaboostclassifier   
8097         49  7472.0  0.883320  randomforestclassifier   
8098         49  4395.0  0.840184  randomforestclassifier   
8099         49  3072.0  0.951673  randomforestclassifier   

      average_abs_odds_difference        f1 subset_label  num_features  \
0                             NaN       NaN         test            11   
1                             NaN       NaN        train            11   
2                             NaN       NaN         test            11   
3                             NaN       NaN        train            11   
4                             NaN       NaN         test            11   
...                           ...       ...          ...           ...   
8095                          NaN  0.640889         test             3   
8096                          NaN  0.538462         test             3   
8097                     0.121756  0.592769         test             3   
8098                          NaN  0.603270         test             3   
8099                          NaN  0.506297         test             3   

      true_positive_rate_difference  accuracy  statistical_parity_difference  \
0                               NaN       NaN                      -0.199292   
1                               NaN       NaN                      -0.198756   
2                               NaN       NaN                            NaN   
3                               NaN       NaN                            NaN   
4                               NaN       NaN                            NaN   
...                             ...       ...                            ...   
8095                            NaN  0.788509                            NaN   
8096                            NaN  0.911596                            NaN   
8097                      -0.129471  0.803733                      -0.199632   
8098                            NaN  0.758670                            NaN   
8099                            NaN  0.893042                            NaN   

      disparate_impact     FP  
0             0.359190    NaN  
1             0.364929    NaN  
2                  NaN    NaN  
3                  NaN    NaN  
4                  NaN    NaN  
...                ...    ...  
8095               NaN  648.0  
8096               NaN   76.0  
8097          0.322954  987.0  
8098               NaN  836.0  
8099               NaN  156.0  

[8100 rows x 26 columns]
#+end_example

#+begin_src python
  data.dtypes
#+end_src

#+RESULTS:
#+begin_example
num_features                       int64
f1                               float64
iteration                          int64
accuracy                         float64
statistical_parity_difference    float64
FNR                              float64
model                             object
TP                               float64
average_abs_odds_difference      float64
privileged                        object
base_rate                        float64
disparate_impact                 float64
FPR                              float64
num_positives                    float64
TNR                              float64
FN                               float64
true_positive_rate_difference    float64
TN                               float64
TPR                              float64
PPV                              float64
protected                         object
num_negatives                    float64
FP                               float64
theil_index                      float64
subset_label                      object
dataset_label                     object
dtype: object
#+end_example

* Disparate Impact & Statistical Parity Difference [0/3]
In this section we take a closer look at the disparate impact &
statistical parity difference metrics. We start with these two since
we have both data & model variants for these metrics.

#+begin_src python
  # fairness metrics are calculated without conditioning on any (un)privileged group
  data = data[data["privileged"] == "None"]

  from src.data import process
  process(data)

  data
#+end_src

#+RESULTS:
#+begin_example
      theil_index  base_rate       PPV  num_negatives dataset_label       FPR  \
0             NaN   0.245356       NaN         8532.0         adult       NaN   
1             NaN   0.248673       NaN        25482.0         adult       NaN   
6        0.124397        NaN  0.723552            NaN         adult  0.074426   
9        0.128685        NaN  0.642722            NaN         adult  0.110759   
12       0.115566        NaN  0.740552            NaN         adult  0.071613   
...           ...        ...       ...            ...           ...       ...   
8083          NaN   0.246521       NaN        25555.0         adult       NaN   
8088     0.144553        NaN  0.679565            NaN         adult  0.087126   
8091     0.158254        NaN  0.591499            NaN         adult  0.122710   
8094     0.137305        NaN  0.692569            NaN         adult  0.085589   
8097     0.145611        NaN  0.620676            NaN         adult  0.116680   

           TPR      FN privileged  num_positives       FNR      TP protected  \
0          NaN     NaN       None         2774.0       NaN     NaN       sex   
1          NaN     NaN       None         8434.0       NaN     NaN       sex   
6     0.599135  1112.0       None            NaN  0.400865  1662.0       sex   
9     0.612833  1074.0       None            NaN  0.387167  1700.0       sex   
12    0.628695  1030.0       None            NaN  0.371305  1744.0       sex   
...        ...     ...        ...            ...       ...     ...       ...   
8083       NaN     NaN       None         8361.0       NaN     NaN       sex   
8088  0.548999  1284.0       None            NaN  0.451001  1563.0       sex   
8091  0.527924  1344.0       None            NaN  0.472076  1503.0       sex   
8094  0.572884  1216.0       None            NaN  0.427116  1631.0       sex   
8097  0.567264  1232.0       None            NaN  0.432736  1615.0       sex   

      iteration      TN       TNR                   model  \
0             0     NaN       NaN                    None   
1             0     NaN       NaN                    None   
6             0  7897.0  0.925574      logisticregression   
9             0  7587.0  0.889241  decisiontreeclassifier   
12            0  7921.0  0.928387      adaboostclassifier   
...         ...     ...       ...                     ...   
8083         49     NaN       NaN                    None   
8088         49  7722.0  0.912874      logisticregression   
8091         49  7421.0  0.877290  decisiontreeclassifier   
8094         49  7735.0  0.914411      adaboostclassifier   
8097         49  7472.0  0.883320  randomforestclassifier   

      average_abs_odds_difference        f1 subset_label  num_features  \
0                             NaN       NaN         test            11   
1                             NaN       NaN        train            11   
6                        0.064530  0.655492         test            11   
9                        0.071917  0.627422         test            11   
12                       0.109763  0.680055         test            11   
...                           ...       ...          ...           ...   
8083                          NaN       NaN        train             3   
8088                     0.120423  0.607344         test             3   
8091                     0.107841  0.557906         test             3   
8094                     0.133089  0.627067         test             3   
8097                     0.121756  0.592769         test             3   

      true_positive_rate_difference  accuracy  statistical_parity_difference  \
0                               NaN       NaN                       0.199292   
1                               NaN       NaN                       0.198756   
6                          0.054410  0.845480                       0.172818   
9                          0.059213  0.821422                       0.177072   
12                         0.140088  0.854856                       0.195283   
...                             ...       ...                            ...   
8083                            NaN       NaN                       0.199805   
8088                       0.143037  0.821245                       0.190791   
8091                       0.115437  0.789315                       0.177518   
8094                       0.165846  0.828410                       0.201219   
8097                       0.129471  0.803733                       0.199632   

      disparate_impact      FP  
0             0.294056     NaN  
1             0.259817     NaN  
6             0.435118   635.0  
9             0.085484   945.0  
12            0.744550   611.0  
...                ...     ...  
8083          0.297740     NaN  
8088          0.761768   737.0  
8091          0.222661  1038.0  
8094          0.859874   724.0  
8097          0.510235   987.0  

[2700 rows x 26 columns]
#+end_example

Lets create a simple lineplot to observe the general trend of the
fairness metrics across various feature sets. Since different datasets
have different protected attributes, we need to create separate
figures for each dataset.

We have data fairness metrics from both the training & testing sets
which we want to compare against the model fairness metrics.

#+begin_src python :results file
  name = "lineplot--exp-feature-sets--adult-sex--di-spd.svg"
  cols = ["disparate_impact", "statistical_parity_difference"]

  fig, axs = plt.subplots(
      nrows=2,
      ncols=2,
      figsize=(10,10),
      sharey=True,
  )

  # top row: data(test) vs model
  for idx, metric in enumerate(cols):
      ax = axs[0,idx]
      ax.set_ylabel(metric)
      sns.lineplot(
          data=data[data["subset_label"] == "test"],
          x="num_features",
          y=metric,
          hue="model",
          style="model",
          ax=ax,
      )

  # bottom row: data(train) vs model
  _ = data
  _.loc[(_["model"] != "None"), "subset_label"] = "train"
  for idx, metric in enumerate(cols):
      ax = axs[1, idx]
      ax.set_ylabel(metric)
      sns.lineplot(
          data=_,
          x="num_features",
          y=metric,
          hue="model",
          style="model",
          ax=ax
      )

  fig.savefig(name, format="svg")
  name
#+end_src

#+RESULTS:
[[file:lineplot--exp-feature-sets--adult-sex--di-spd.svg]]

* Summary of results
We want to create a summary of the results from the linear regression
models. We want to collect the following metrics:
1. min & max of x (data metrics) & y (model metrics)
2. average of x & y
3. slope of the regression line
4. correlation between x & y

Lets combine all the datasets so that we can collect the results in a
single table.

#+begin_src python
  import glob

  frames = [pd.read_csv(frame) for frame in glob.glob(os.path.join(DATADIR, "exp-feature-sets-*-50.csv"))]

  data = pd.concat(frames)

  data.shape
#+end_src

#+RESULTS:
| 112500 | 26 |

#+begin_src python
  data.dtypes
#+end_src

#+RESULTS:
#+begin_example
theil_index                      float64
base_rate                        float64
PPV                              float64
num_negatives                    float64
dataset_label                     object
FPR                              float64
TPR                              float64
FN                               float64
privileged                        object
num_positives                    float64
FNR                              float64
TP                               float64
protected                         object
iteration                          int64
TN                               float64
TNR                              float64
model                             object
average_abs_odds_difference      float64
f1                               float64
subset_label                      object
num_features                       int64
true_positive_rate_difference    float64
accuracy                         float64
statistical_parity_difference    float64
disparate_impact                 float64
FP                               float64
dtype: object
#+end_example

#+begin_src python
  data["dataset_label"].unique()
#+end_src

#+RESULTS:
| adult | german | compas | bank | meps |

Lets focus on DI & SPD only next.

#+begin_src python
  cols = [
      "dataset_label",
      "subset_label",
      "protected",
      "iteration",
      "model",
      "num_features",
      "statistical_parity_difference",
      "disparate_impact",
  ]

  data = data[data["privileged"] == "None"]
  data = data[cols]
  data.shape
#+end_src

#+RESULTS:
| 37500 | 8 |

Lets gather the correlation between the data & model metrics. We will
create two separate datasets, one for each metric.

#+begin_src python
  from src.data import pivot_frame

  def pivot_data(data, var, values):
      _pivots = []
      for n in data[var].unique().tolist():
          _pivot = pivot_frame(data[data[var] == n], values)
          _pivot[var] = n
          _pivot["metric"] = values
          _pivots.append(_pivot)
      return pd.concat(_pivots)

  for dataset in data["dataset_label"].unique().tolist():
      for protected in data[data["dataset_label"] == dataset]["protected"].unique().tolist():
          for subset in
#+end_src
