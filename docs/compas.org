#+title: Compas
#+author: Arumoy Shome
#+date: [2022-08-21 Sun]
#+property: header-args:python :session *sh21qual-compas* :exports both :eval never-export

In this file we analyse the results for the compas dataset. The
dataset contains two protected attributes: sex & race. We consider
both protected attributes individually in our analysis.

The data analysed here is generated using =bin/data.py=.

* Init
In this section we load the necessary modules & the dataset.

#+begin_src python :results silent
  import pandas as pd
  import numpy as np
  pd.set_option('display.max_columns', None)
  pd.set_option('display.max_colwidth', None)
  pd.set_option('display.max_rows', None)

  import matplotlib
  matplotlib.use('Agg')           # non-interactive backend
  import matplotlib.pyplot as plt
  import seaborn as sns

  import os
  import sys
  ROOTDIR = os.path.abspath(os.path.join(os.getcwd(), '..'))
  DATADIR = os.path.join(ROOTDIR, 'data')

  sys.path.insert(0, ROOTDIR)
  from src import utils
#+end_src

#+begin_src python :results silent
  compas = pd.read_csv(os.path.join(DATADIR, 'data.csv'))
  compas = compas[compas['dataset'] == 'compas']
#+end_src

* Priliminary analysis
In this section we conduct some priliminary analysis of the dataset.

#+begin_src python
  compas
#+end_src

#+RESULTS:
#+begin_example
   dataset  GFNR  num_negatives  disparate_impact       FDR  \
30  compas   NaN         2809.0          0.802925       NaN   
31  compas   NaN          413.0               NaN       NaN   
32  compas   NaN         2396.0               NaN       NaN   
33  compas   NaN         2809.0          0.840384       NaN   
34  compas   NaN          822.0               NaN       NaN   
35  compas   NaN         1987.0               NaN       NaN   
36  compas   NaN         2110.0          0.815364       NaN   
37  compas   NaN          322.0               NaN       NaN   
38  compas   NaN         1788.0               NaN       NaN   
39  compas   NaN         2110.0          0.846523       NaN   
40  compas   NaN          632.0               NaN       NaN   
41  compas   NaN         1478.0               NaN       NaN   
42  compas   NaN          699.0          0.765863       NaN   
43  compas   NaN           91.0               NaN       NaN   
44  compas   NaN          608.0               NaN       NaN   
45  compas   NaN          699.0          0.821505       NaN   
46  compas   NaN          190.0               NaN       NaN   
47  compas   NaN          509.0               NaN       NaN   
48  compas   0.0            NaN          0.681849  0.334737   
49  compas   0.0            NaN               NaN  0.277778   
50  compas   0.0            NaN               NaN  0.353352   
51  compas   0.0            NaN          0.740128  0.334737   
52  compas   0.0            NaN               NaN  0.306667   
53  compas   0.0            NaN               NaN  0.353043   
54  compas   0.0            NaN          0.752926  0.371396   
55  compas   0.0            NaN               NaN  0.272727   
56  compas   0.0            NaN               NaN  0.400598   
57  compas   0.0            NaN          0.833327  0.371396   
58  compas   0.0            NaN               NaN  0.345912   
59  compas   0.0            NaN               NaN  0.386157   

    statistical_parity_difference       FPR       PPV    GTP    GTN       NPV  \
30                      -0.127687       NaN       NaN    NaN    NaN       NaN   
31                            NaN       NaN       NaN    NaN    NaN       NaN   
32                            NaN       NaN       NaN    NaN    NaN       NaN   
33                      -0.097138       NaN       NaN    NaN    NaN       NaN   
34                            NaN       NaN       NaN    NaN    NaN       NaN   
35                            NaN       NaN       NaN    NaN    NaN       NaN   
36                      -0.117985       NaN       NaN    NaN    NaN       NaN   
37                            NaN       NaN       NaN    NaN    NaN       NaN   
38                            NaN       NaN       NaN    NaN    NaN       NaN   
39                      -0.092778       NaN       NaN    NaN    NaN       NaN   
40                            NaN       NaN       NaN    NaN    NaN       NaN   
41                            NaN       NaN       NaN    NaN    NaN       NaN   
42                      -0.158314       NaN       NaN    NaN    NaN       NaN   
43                            NaN       NaN       NaN    NaN    NaN       NaN   
44                            NaN       NaN       NaN    NaN    NaN       NaN   
45                      -0.110937       NaN       NaN    NaN    NaN       NaN   
46                            NaN       NaN       NaN    NaN    NaN       NaN   
47                            NaN       NaN       NaN    NaN    NaN       NaN   
48                      -0.264937  0.454936  0.665263  843.0  699.0  0.643581   
49                            NaN  0.714286  0.722222  190.0   91.0  0.553191   
50                            NaN  0.416118  0.646648  653.0  608.0  0.651376   
51                      -0.194127  0.454936  0.665263  843.0  699.0  0.643581   
52                            NaN  0.605263  0.693333  312.0  190.0  0.590551   
53                            NaN  0.398821  0.646957  531.0  509.0  0.658065   
54                      -0.174095  0.460658  0.628604  843.0  699.0  0.558519   
55                            NaN  0.593407  0.727273  190.0   91.0  0.445783   
56                            NaN  0.440789  0.599402  653.0  608.0  0.574324   
57                      -0.105582  0.460658  0.628604  843.0  699.0  0.558519   
58                            NaN  0.578947  0.654088  312.0  190.0  0.434783   
59                            NaN  0.416503  0.613843  531.0  509.0  0.604888   

          f1  GFP  base_rate  theil_index                   model       TPR  \
30       NaN  NaN   0.544511          NaN                    None       NaN   
31       NaN  NaN   0.647911          NaN                    None       NaN   
32       NaN  NaN   0.520224          NaN                    None       NaN   
33       NaN  NaN   0.544511          NaN                    None       NaN   
34       NaN  NaN   0.608571          NaN                    None       NaN   
35       NaN  NaN   0.511433          NaN                    None       NaN   
36       NaN  NaN   0.543784          NaN                    None       NaN   
37       NaN  NaN   0.639013          NaN                    None       NaN   
38       NaN  NaN   0.521029          NaN                    None       NaN   
39       NaN  NaN   0.543784          NaN                    None       NaN   
40       NaN  NaN   0.604506          NaN                    None       NaN   
41       NaN  NaN   0.511728          NaN                    None       NaN   
42       NaN  NaN   0.546693          NaN                    None       NaN   
43       NaN  NaN   0.676157          NaN                    None       NaN   
44       NaN  NaN   0.517843          NaN                    None       NaN   
45       NaN  NaN   0.546693          NaN                    None       NaN   
46       NaN  NaN   0.621514          NaN                    None       NaN   
47       NaN  NaN   0.510577          NaN                    None       NaN   
48  0.704964  0.0        NaN     0.200250      logisticregression  0.749703   
49  0.797170  0.0        NaN          NaN      logisticregression  0.889474   
50  0.676406  0.0        NaN          NaN      logisticregression  0.709035   
51  0.704964  0.0        NaN     0.200250      logisticregression  0.749703   
52  0.756914  0.0        NaN          NaN      logisticregression  0.833333   
53  0.672694  0.0        NaN          NaN      logisticregression  0.700565   
54  0.637427  0.0        NaN     0.269605  decisiontreeclassifier  0.646501   
55  0.742268  0.0        NaN          NaN  decisiontreeclassifier  0.757895   
56  0.606657  0.0        NaN          NaN  decisiontreeclassifier  0.614089   
57  0.637427  0.0        NaN     0.269605  decisiontreeclassifier  0.646501   
58  0.660317  0.0        NaN          NaN  decisiontreeclassifier  0.666667   
59  0.624074  0.0        NaN          NaN  decisiontreeclassifier  0.634652   

    num_positives     TP     TN     FP       FOR subset  GTNR protected  \
30         3358.0    NaN    NaN    NaN       NaN   full   NaN       sex   
31          760.0    NaN    NaN    NaN       NaN   full   NaN       sex   
32         2598.0    NaN    NaN    NaN       NaN   full   NaN       sex   
33         3358.0    NaN    NaN    NaN       NaN   full   NaN      race   
34         1278.0    NaN    NaN    NaN       NaN   full   NaN      race   
35         2080.0    NaN    NaN    NaN       NaN   full   NaN      race   
36         2515.0    NaN    NaN    NaN       NaN  train   NaN       sex   
37          570.0    NaN    NaN    NaN       NaN  train   NaN       sex   
38         1945.0    NaN    NaN    NaN       NaN  train   NaN       sex   
39         2515.0    NaN    NaN    NaN       NaN  train   NaN      race   
40          966.0    NaN    NaN    NaN       NaN  train   NaN      race   
41         1549.0    NaN    NaN    NaN       NaN  train   NaN      race   
42          843.0    NaN    NaN    NaN       NaN   test   NaN       sex   
43          190.0    NaN    NaN    NaN       NaN   test   NaN       sex   
44          653.0    NaN    NaN    NaN       NaN   test   NaN       sex   
45          843.0    NaN    NaN    NaN       NaN   test   NaN      race   
46          312.0    NaN    NaN    NaN       NaN   test   NaN      race   
47          531.0    NaN    NaN    NaN       NaN   test   NaN      race   
48            NaN  632.0  381.0  318.0  0.356419   test   1.0       sex   
49            NaN  169.0   26.0   65.0  0.446809   test   1.0       sex   
50            NaN  463.0  355.0  253.0  0.348624   test   1.0       sex   
51            NaN  632.0  381.0  318.0  0.356419   test   1.0      race   
52            NaN  260.0   75.0  115.0  0.409449   test   1.0      race   
53            NaN  372.0  306.0  203.0  0.341935   test   1.0      race   
54            NaN  545.0  377.0  322.0  0.441481   test   1.0       sex   
55            NaN  144.0   37.0   54.0  0.554217   test   1.0       sex   
56            NaN  401.0  340.0  268.0  0.425676   test   1.0       sex   
57            NaN  545.0  377.0  322.0  0.441481   test   1.0      race   
58            NaN  208.0   80.0  110.0  0.565217   test   1.0      race   
59            NaN  337.0  297.0  212.0  0.395112   test   1.0      race   

         TNR     FN privileged       FNR  accuracy  GFPR  GTPR  GFN  
30       NaN    NaN       None       NaN       NaN   NaN   NaN  NaN  
31       NaN    NaN       True       NaN       NaN   NaN   NaN  NaN  
32       NaN    NaN      False       NaN       NaN   NaN   NaN  NaN  
33       NaN    NaN       None       NaN       NaN   NaN   NaN  NaN  
34       NaN    NaN       True       NaN       NaN   NaN   NaN  NaN  
35       NaN    NaN      False       NaN       NaN   NaN   NaN  NaN  
36       NaN    NaN       None       NaN       NaN   NaN   NaN  NaN  
37       NaN    NaN       True       NaN       NaN   NaN   NaN  NaN  
38       NaN    NaN      False       NaN       NaN   NaN   NaN  NaN  
39       NaN    NaN       None       NaN       NaN   NaN   NaN  NaN  
40       NaN    NaN       True       NaN       NaN   NaN   NaN  NaN  
41       NaN    NaN      False       NaN       NaN   NaN   NaN  NaN  
42       NaN    NaN       None       NaN       NaN   NaN   NaN  NaN  
43       NaN    NaN       True       NaN       NaN   NaN   NaN  NaN  
44       NaN    NaN      False       NaN       NaN   NaN   NaN  NaN  
45       NaN    NaN       None       NaN       NaN   NaN   NaN  NaN  
46       NaN    NaN       True       NaN       NaN   NaN   NaN  NaN  
47       NaN    NaN      False       NaN       NaN   NaN   NaN  NaN  
48  0.545064  211.0       None  0.250297  0.656939   0.0   1.0  0.0  
49  0.285714   21.0       True  0.110526  0.693950   0.0   1.0  0.0  
50  0.583882  190.0      False  0.290965  0.648692   0.0   1.0  0.0  
51  0.545064  211.0       None  0.250297  0.656939   0.0   1.0  0.0  
52  0.394737   52.0       True  0.166667  0.667331   0.0   1.0  0.0  
53  0.601179  159.0      False  0.299435  0.651923   0.0   1.0  0.0  
54  0.539342  298.0       None  0.353499  0.597925   0.0   1.0  0.0  
55  0.406593   46.0       True  0.242105  0.644128   0.0   1.0  0.0  
56  0.559211  252.0      False  0.385911  0.587629   0.0   1.0  0.0  
57  0.539342  298.0       None  0.353499  0.597925   0.0   1.0  0.0  
58  0.421053  104.0       True  0.333333  0.573705   0.0   1.0  0.0  
59  0.583497  194.0      False  0.365348  0.609615   0.0   1.0  0.0  
#+end_example

#+begin_src python
  compas.shape
#+end_src

#+RESULTS:
| 30 | 33 |

#+begin_src python
  compas.dtypes
#+end_src

#+RESULTS:
#+begin_example
dataset                           object
GFNR                             float64
num_negatives                    float64
disparate_impact                 float64
FDR                              float64
statistical_parity_difference    float64
FPR                              float64
PPV                              float64
GTP                              float64
GTN                              float64
NPV                              float64
f1                               float64
GFP                              float64
base_rate                        float64
theil_index                      float64
model                             object
TPR                              float64
num_positives                    float64
TP                               float64
TN                               float64
FP                               float64
FOR                              float64
subset                            object
GTNR                             float64
protected                         object
TNR                              float64
FN                               float64
privileged                        object
FNR                              float64
accuracy                         float64
GFPR                             float64
GTPR                             float64
GFN                              float64
dtype: object
#+end_example

#+begin_src python
  compas.describe(include='all')
#+end_src

#+RESULTS:
#+begin_example
       dataset  GFNR  num_negatives  disparate_impact        FDR  \
count       30  12.0      18.000000         10.000000  12.000000   
unique       1   NaN            NaN               NaN        NaN   
top     compas   NaN            NaN               NaN        NaN   
freq        30   NaN            NaN               NaN        NaN   
mean       NaN   0.0    1248.444444          0.790079   0.342375   
std        NaN   0.0     929.902602          0.053286   0.040061   
min        NaN   0.0      91.000000          0.681849   0.272727   
25%        NaN   0.0     533.750000          0.756160   0.327719   
50%        NaN   0.0     760.500000          0.809145   0.349478   
75%        NaN   0.0    2079.250000          0.830372   0.371396   
max        NaN   0.0    2809.000000          0.846523   0.400598   

        statistical_parity_difference        FPR        PPV         GTP  \
count                       10.000000  12.000000  12.000000   12.000000   
unique                            NaN        NaN        NaN         NaN   
top                               NaN        NaN        NaN         NaN   
freq                              NaN        NaN        NaN         NaN   
mean                        -0.144358   0.499610   0.657625  562.000000   
std                          0.054344   0.098564   0.040061  258.684785   
min                         -0.264937   0.398821   0.599402  190.000000   
25%                         -0.170150   0.434718   0.628604  312.000000   
50%                         -0.122836   0.457797   0.650522  592.000000   
75%                         -0.106920   0.582562   0.672281  843.000000   
max                         -0.092778   0.714286   0.727273  843.000000   

               GTN        NPV         f1   GFP  base_rate  theil_index model  \
count    12.000000  12.000000  12.000000  12.0  18.000000     4.000000    30   
unique         NaN        NaN        NaN   NaN        NaN          NaN     3   
top            NaN        NaN        NaN   NaN        NaN          NaN  None   
freq           NaN        NaN        NaN   NaN        NaN          NaN    18   
mean    466.000000   0.576430   0.685107   0.0   0.564471     0.234927   NaN   
std     251.320874   0.074240   0.058029   0.0   0.053467     0.040042   NaN   
min      91.000000   0.434783   0.606657   0.0   0.510577     0.200250   NaN   
25%     190.000000   0.557187   0.637427   0.0   0.520425     0.200250   NaN   
50%     558.500000   0.582438   0.674550   0.0   0.544511     0.234927   NaN   
75%     699.000000   0.643581   0.714290   0.0   0.607555     0.269605   NaN   
max     699.000000   0.658065   0.797170   0.0   0.676157     0.269605   NaN   

              TPR  num_positives          TP          TN          FP  \
count   12.000000      18.000000   12.000000   12.000000   12.000000   
unique        NaN            NaN         NaN         NaN         NaN   
top           NaN            NaN         NaN         NaN         NaN   
freq          NaN            NaN         NaN         NaN         NaN   
mean     0.716510    1492.444444  392.333333  252.666667  213.333333   
std      0.083812    1031.852487  174.010623  149.555300  103.543872   
min      0.614089     190.000000  144.000000   26.000000   54.000000   
25%      0.646501     679.750000  247.000000   78.750000  113.750000   
50%      0.704800    1122.000000  386.500000  323.000000  232.500000   
75%      0.751751    2406.250000  545.000000  377.000000  318.000000   
max      0.889474    3358.000000  632.000000  381.000000  322.000000   

              FOR subset  GTNR protected        TNR          FN privileged  \
count   12.000000     30  12.0        30  12.000000   12.000000         30   
unique        NaN      3   NaN         2        NaN         NaN          3   
top           NaN   test   NaN       sex        NaN         NaN       None   
freq          NaN     18   NaN        15        NaN         NaN         10   
mean     0.423570    NaN   1.0       NaN   0.500390  169.666667        NaN   
std      0.074240    NaN   0.0       NaN   0.098564   95.254046        NaN   
min      0.341935    NaN   1.0       NaN   0.285714   21.000000        NaN   
25%      0.356419    NaN   1.0       NaN   0.417438   91.000000        NaN   
50%      0.417562    NaN   1.0       NaN   0.542203  192.000000        NaN   
75%      0.442813    NaN   1.0       NaN   0.565282  221.250000        NaN   
max      0.565217    NaN   1.0       NaN   0.601179  298.000000        NaN   

              FNR   accuracy  GFPR  GTPR   GFN  
count   12.000000  12.000000  12.0  12.0  12.0  
unique        NaN        NaN   NaN   NaN   NaN  
top           NaN        NaN   NaN   NaN   NaN  
freq          NaN        NaN   NaN   NaN   NaN  
mean     0.283490   0.632225   0.0   1.0   0.0  
std      0.083812   0.037347   0.0   0.0   0.0  
min      0.110526   0.573705   0.0   1.0   0.0  
25%      0.248249   0.597925   0.0   1.0   0.0  
50%      0.295200   0.646410   0.0   1.0   0.0  
75%      0.353499   0.656939   0.0   1.0   0.0  
max      0.385911   0.693950   0.0   1.0   0.0  
#+end_example

* Analysis of protected attribute =sex=

#+begin_src python
  data = compas[compas['protected'] == 'sex']
  data.shape
#+end_src

#+RESULTS:
| 15 | 33 |

#+begin_src python
  data
#+end_src

#+RESULTS:
#+begin_example
   dataset  GFNR  num_negatives  disparate_impact       FDR  \
30  compas   NaN         2809.0          0.802925       NaN   
31  compas   NaN          413.0               NaN       NaN   
32  compas   NaN         2396.0               NaN       NaN   
36  compas   NaN         2110.0          0.815364       NaN   
37  compas   NaN          322.0               NaN       NaN   
38  compas   NaN         1788.0               NaN       NaN   
42  compas   NaN          699.0          0.765863       NaN   
43  compas   NaN           91.0               NaN       NaN   
44  compas   NaN          608.0               NaN       NaN   
48  compas   0.0            NaN          0.681849  0.334737   
49  compas   0.0            NaN               NaN  0.277778   
50  compas   0.0            NaN               NaN  0.353352   
54  compas   0.0            NaN          0.752926  0.371396   
55  compas   0.0            NaN               NaN  0.272727   
56  compas   0.0            NaN               NaN  0.400598   

    statistical_parity_difference       FPR       PPV    GTP    GTN       NPV  \
30                      -0.127687       NaN       NaN    NaN    NaN       NaN   
31                            NaN       NaN       NaN    NaN    NaN       NaN   
32                            NaN       NaN       NaN    NaN    NaN       NaN   
36                      -0.117985       NaN       NaN    NaN    NaN       NaN   
37                            NaN       NaN       NaN    NaN    NaN       NaN   
38                            NaN       NaN       NaN    NaN    NaN       NaN   
42                      -0.158314       NaN       NaN    NaN    NaN       NaN   
43                            NaN       NaN       NaN    NaN    NaN       NaN   
44                            NaN       NaN       NaN    NaN    NaN       NaN   
48                      -0.264937  0.454936  0.665263  843.0  699.0  0.643581   
49                            NaN  0.714286  0.722222  190.0   91.0  0.553191   
50                            NaN  0.416118  0.646648  653.0  608.0  0.651376   
54                      -0.174095  0.460658  0.628604  843.0  699.0  0.558519   
55                            NaN  0.593407  0.727273  190.0   91.0  0.445783   
56                            NaN  0.440789  0.599402  653.0  608.0  0.574324   

          f1  GFP  base_rate  theil_index                   model       TPR  \
30       NaN  NaN   0.544511          NaN                    None       NaN   
31       NaN  NaN   0.647911          NaN                    None       NaN   
32       NaN  NaN   0.520224          NaN                    None       NaN   
36       NaN  NaN   0.543784          NaN                    None       NaN   
37       NaN  NaN   0.639013          NaN                    None       NaN   
38       NaN  NaN   0.521029          NaN                    None       NaN   
42       NaN  NaN   0.546693          NaN                    None       NaN   
43       NaN  NaN   0.676157          NaN                    None       NaN   
44       NaN  NaN   0.517843          NaN                    None       NaN   
48  0.704964  0.0        NaN     0.200250      logisticregression  0.749703   
49  0.797170  0.0        NaN          NaN      logisticregression  0.889474   
50  0.676406  0.0        NaN          NaN      logisticregression  0.709035   
54  0.637427  0.0        NaN     0.269605  decisiontreeclassifier  0.646501   
55  0.742268  0.0        NaN          NaN  decisiontreeclassifier  0.757895   
56  0.606657  0.0        NaN          NaN  decisiontreeclassifier  0.614089   

    num_positives     TP     TN     FP       FOR subset  GTNR protected  \
30         3358.0    NaN    NaN    NaN       NaN   full   NaN       sex   
31          760.0    NaN    NaN    NaN       NaN   full   NaN       sex   
32         2598.0    NaN    NaN    NaN       NaN   full   NaN       sex   
36         2515.0    NaN    NaN    NaN       NaN  train   NaN       sex   
37          570.0    NaN    NaN    NaN       NaN  train   NaN       sex   
38         1945.0    NaN    NaN    NaN       NaN  train   NaN       sex   
42          843.0    NaN    NaN    NaN       NaN   test   NaN       sex   
43          190.0    NaN    NaN    NaN       NaN   test   NaN       sex   
44          653.0    NaN    NaN    NaN       NaN   test   NaN       sex   
48            NaN  632.0  381.0  318.0  0.356419   test   1.0       sex   
49            NaN  169.0   26.0   65.0  0.446809   test   1.0       sex   
50            NaN  463.0  355.0  253.0  0.348624   test   1.0       sex   
54            NaN  545.0  377.0  322.0  0.441481   test   1.0       sex   
55            NaN  144.0   37.0   54.0  0.554217   test   1.0       sex   
56            NaN  401.0  340.0  268.0  0.425676   test   1.0       sex   

         TNR     FN privileged       FNR  accuracy  GFPR  GTPR  GFN  
30       NaN    NaN       None       NaN       NaN   NaN   NaN  NaN  
31       NaN    NaN       True       NaN       NaN   NaN   NaN  NaN  
32       NaN    NaN      False       NaN       NaN   NaN   NaN  NaN  
36       NaN    NaN       None       NaN       NaN   NaN   NaN  NaN  
37       NaN    NaN       True       NaN       NaN   NaN   NaN  NaN  
38       NaN    NaN      False       NaN       NaN   NaN   NaN  NaN  
42       NaN    NaN       None       NaN       NaN   NaN   NaN  NaN  
43       NaN    NaN       True       NaN       NaN   NaN   NaN  NaN  
44       NaN    NaN      False       NaN       NaN   NaN   NaN  NaN  
48  0.545064  211.0       None  0.250297  0.656939   0.0   1.0  0.0  
49  0.285714   21.0       True  0.110526  0.693950   0.0   1.0  0.0  
50  0.583882  190.0      False  0.290965  0.648692   0.0   1.0  0.0  
54  0.539342  298.0       None  0.353499  0.597925   0.0   1.0  0.0  
55  0.406593   46.0       True  0.242105  0.644128   0.0   1.0  0.0  
56  0.559211  252.0      False  0.385911  0.587629   0.0   1.0  0.0  
#+end_example

** Analysis of fairness metrics

We start with the =num_positives=, =num_negatives= which are computed
only using the dataset.

#+begin_src python :results file
  name = 'compas_barplot_prot-sex_subset-all_num-pos-neg'

  fig, axs = plt.subplots(1, 2, sharey=True, figsize=(10, 5))

  sns.barplot(data=data,
	      y='num_positives',
	      x='subset',
	      hue='privileged',
	      hue_order=['None', 'True', 'False'],
	      ax=axs[0])

  sns.barplot(data=data,
	      y='num_negatives',
	      x='subset',
	      hue='privileged',
	      hue_order=['None', 'True', 'False'],
	      ax=axs[1])

  # label the bars with the value, taken from
  # <https://stackoverflow.com/a/68323374>
  for container in axs[0].containers:
      axs[0].bar_label(container)

  for container in axs[1].containers:
      axs[1].bar_label(container)

  utils.savefig(fig, name)
#+end_src

#+RESULTS:
[[file:compas_barplot_prot-sex_subset-all_num-pos-neg.png]]

The dataset is mostly balanced with slightly more number of examples
from the positive class. However the data does contain more examples
of the unprivileged group than the privileged group.

*** Analysis of =base_rate=

#+begin_src python :results file
  name = 'compas_barplot_prot-sex_base-rate'

  fig, ax = plt.subplots()

  sns.barplot(data=data,
	      y='base_rate',
	      x='subset',
	      hue='privileged',
	      hue_order=['None', 'True', 'False'],
	      ax=ax)

  for container in ax.containers:
      ax.bar_label(container)

  utils.savefig(fig, name)

#+end_src

#+RESULTS:
[[file:compas_barplot_prot-sex_base-rate.png]]

The unconditioned =base_rate= is ~55% and this makes sense since we
have slightly more number of examples for the positive class.

The =base_rate= across the various subsets is similar since we derived
the training & testing sets via random sampling.

The =base_rate= for the privileged group is higher compared to the
unprivileged group. This may seem counter-intuitive given that we have
more examples of the unprivileged group in the dataset. However the
maths is sound, as shown below. I derive the =base_rate= for the test
subset manually, as shown below.

\begin{equation}
\text{positive class examples} = 843 \\
\text{negative class examples} = 699 \\
\text{total examples} = 1542 \\
\\
\text{privileged, positive class examples} = 190 \\
\text{privileged, negative class examples} = 91 \\
\text{total privileged class examples} = 281 \\
\\
\text{unprivileged, positive class examples} = 653 \\
\text{unprivileged, negative class examples} = 608 \\
\text{total privileged class examples} = 1261 \\
\\
P(Y=1) = \frac{843}{1542} = 0.546693
\end{equation}

\begin{equation}
P(Y=1 | D=\text{privileged}) = \frac{P(Y=1 \cap D=\text{privileged})}{P(D=\text{privileged})} \\
= \frac{\frac{190}{1542}}{\frac{281}{1542}} \\
= 0.676157
\end{equation}

\begin{equation}
P(Y=1 | D=\text{unprivileged}) = \frac{P(Y=1 \cap D=\text{unprivileged})}{P(D=\text{unprivileged})} \\
= \frac{\frac{653}{1542}}{\frac{1261}{1542}} \\
= 0.517843
\end{equation}

Note that values obtained for $P(Y=1)$, $P(Y=1 | D=\text{privileged})$
& $P(Y=1 | D=\text{unprivileged})$ match what we see in the figure.

*** Analysis of =disparate_impact=

#+begin_src python :results file
  name = 'compas_barplot_prot-sex_mod-none_disparate-impact'

  fig, ax = plt.subplots()

  sns.barplot(data=data[data['model'] == 'None'],
	      y='disparate_impact',
	      x='subset',
	      ax=ax)

  for container in ax.containers:
      ax.bar_label(container)

  utils.savefig(fig, name)
#+end_src

#+RESULTS:
[[file:compas_barplot_prot-sex_mod-none_disparate-impact.png]]

#+begin_src python :results file
  name = 'compas_barplot_prot-sex_mod-all_disparate-impact'

  fig, ax = plt.subplots()

  sns.barplot(data=data[data['subset'] == 'test'],
	      y='disparate_impact',
	      x='model',
	      ax=ax)

  for container in ax.containers:
      ax.bar_label(container)

  utils.savefig(fig, name)
#+end_src

#+RESULTS:
[[file:compas_barplot_prot-sex_mod-all_disparate-impact.png]]

*** Analysis of =statistical_parity_difference=
#+begin_src python :results file
  name = 'compas_barplot_prot-sex_mod-none_stat-par-diff'

  fig, ax = plt.subplots()

  sns.barplot(data=data[data['model'] == 'None'],
	      y='statistical_parity_difference',
	      x='subset',
	      ax=ax)

  for container in ax.containers:
      ax.bar_label(container)

  utils.savefig(fig, name)
#+end_src

#+RESULTS:
[[file:compas_barplot_prot-sex_mod-none_stat-par-diff.png]]

#+begin_src python :results file
  name = 'compas_barplot_prot-sex_mod-all_stat-par-diff'

  fig, ax = plt.subplots()

  sns.barplot(data=data[data['subset'] == 'test'],
	      y='statistical_parity_difference',
	      x='model',
	      ax=ax)

  for container in ax.containers:
      ax.bar_label(container)

  utils.savefig(fig, name)
#+end_src

#+RESULTS:
[[file:compas_barplot_prot-sex_mod-all_stat-par-diff.png]]

** Analysis of performance metrics
*** model: logisticregression

#+begin_src python :results file
  name = 'compas_heatmap_prot-sex_mod-lr_cm'
  metrics = data[data['model'] == 'logisticregression']
  cols = ['TN', 'FP', 'FN', 'TP']
  fig, axs = plt.subplots(1, 3, figsize=(15, 5))

  for idx, privileged in enumerate(['None', 'True', 'False']):
      cm = metrics[metrics['privileged'] == privileged]
      cm = cm[cols].values.reshape(2,2)
      sns.heatmap(data=cm,
		  annot=cm,
		  fmt="",
		  cbar=False,
		  cmap='Blues',
		  ax=axs[idx])
      axs[idx].set_xlabel("y_pred")
      axs[idx].set_ylabel("y_true")
      axs[idx].set_title(privileged)

  utils.savefig(fig, name)
#+end_src

#+RESULTS:
[[file:compas_heatmap_prot-sex_mod-lr_cm.png]]

#+begin_src python :results file
  name = 'compas_heatmap_prot-sex_mod-lr_cm-rate'
  metrics = data[data['model'] == 'logisticregression']
  cols = ['TNR', 'FPR', 'FNR', 'TPR']
  fig, axs = plt.subplots(1, 3, figsize=(15, 5))

  for idx, privileged in enumerate(['None', 'True', 'False']):
      cm = metrics[metrics['privileged'] == privileged]
      cm = cm[cols].values.reshape(2,2)
      sns.heatmap(data=cm,
		  annot=cm,
		  fmt=".3f",
		  cbar=False,
		  cmap='Blues',
		  ax=axs[idx])
      axs[idx].set_xlabel("y_pred")
      axs[idx].set_ylabel("y_true")
      axs[idx].set_title(privileged)

  utils.savefig(fig, name)
#+end_src

#+RESULTS:
[[file:compas_heatmap_prot-sex_mod-lr_cm-rate.png]]

#+begin_src python :results file
  name = 'compas_barplot_prot-sex_mod-lr_acc-pre-rec-f1'
  metrics = data[data['model'] == 'logisticregression']
  hue_order = ['None', 'True', 'False']

  fig, axs = plt.subplots(1, 4, sharey=True, figsize=(20, 5))

  sns.barplot(data=metrics,
	      y='accuracy',
	      x='subset',
	      hue='privileged',
	      hue_order=hue_order,
	      ax=axs[0])

  sns.barplot(data=metrics,
	      y='PPV',
	      x='subset',
	      hue='privileged',
	      hue_order=hue_order,
	      ax=axs[1])
  axs[1].set_ylabel('precision')

  sns.barplot(data=metrics,
	      y='TPR',
	      x='subset',
	      hue='privileged',
	      hue_order=hue_order,
	      ax=axs[2])
  axs[2].set_ylabel('recall')

  sns.barplot(data=metrics,
	      y='f1',
	      x='subset',
	      hue='privileged',
	      hue_order=hue_order,
	      ax=axs[3])

  for idx in range(4):
      for container in axs[idx].containers: axs[idx].bar_label(container)

  utils.savefig(fig, name)
#+end_src

#+RESULTS:
[[file:compas_barplot_prot-sex_mod-lr_acc-pre-rec-f1.png]]

*** model: decisiontreeclassifier

#+begin_src python :results file
  name = 'compas_heatmap_prot-sex_mod-dt_cm'
  metrics = data[data['model'] == 'decisiontreeclassifier']
  cols = ['TN', 'FP', 'FN', 'TP']
  fig, axs = plt.subplots(1, 3, figsize=(15, 5))

  for idx, privileged in enumerate(['None', 'True', 'False']):
      cm = metrics[metrics['privileged'] == privileged]
      cm = cm[cols].values.reshape(2,2)
      sns.heatmap(data=cm,
		  annot=cm,
		  fmt="",
		  cbar=False,
		  cmap='Blues',
		  ax=axs[idx])
      axs[idx].set_xlabel("y_pred")
      axs[idx].set_ylabel("y_true")
      axs[idx].set_title(privileged)

  utils.savefig(fig, name)
#+end_src

#+RESULTS:
[[file:compas_heatmap_prot-sex_mod-dt_cm.png]]

#+begin_src python :results file
  name = 'compas_heatmap_prot-sex_mod-dt_cm-rate'
  metrics = data[data['model'] == 'decisiontreeclassifier']
  cols = ['TNR', 'FPR', 'FNR', 'TPR']
  fig, axs = plt.subplots(1, 3, figsize=(15, 5))

  for idx, privileged in enumerate(['None', 'True', 'False']):
      cm = metrics[metrics['privileged'] == privileged]
      cm = cm[cols].values.reshape(2,2)
      sns.heatmap(data=cm,
		  annot=cm,
		  fmt=".3f",
		  cbar=False,
		  cmap='Blues',
		  ax=axs[idx])
      axs[idx].set_xlabel("y_pred")
      axs[idx].set_ylabel("y_true")
      axs[idx].set_title(privileged)

  utils.savefig(fig, name)
#+end_src

#+RESULTS:
[[file:compas_heatmap_prot-sex_mod-dt_cm-rate.png]]

#+begin_src python :results file
  name = 'compas_barplot_prot-sex_mod-dt_acc-pre-rec-f1'
  metrics = data[data['model'] == 'decisiontreeclassifier']
  hue_order = ['None', 'True', 'False']

  fig, axs = plt.subplots(1, 4, sharey=True, figsize=(20, 5))

  sns.barplot(data=metrics,
	      y='accuracy',
	      x='subset',
	      hue='privileged',
	      hue_order=hue_order,
	      ax=axs[0])

  sns.barplot(data=metrics,
	      y='PPV',
	      x='subset',
	      hue='privileged',
	      hue_order=hue_order,
	      ax=axs[1])
  axs[1].set_ylabel('precision')

  sns.barplot(data=metrics,
	      y='TPR',
	      x='subset',
	      hue='privileged',
	      hue_order=hue_order,
	      ax=axs[2])
  axs[2].set_ylabel('recall')

  sns.barplot(data=metrics,
	      y='f1',
	      x='subset',
	      hue='privileged',
	      hue_order=hue_order,
	      ax=axs[3])

  for idx in range(4):
      for container in axs[idx].containers: axs[idx].bar_label(container)

  utils.savefig(fig, name)
#+end_src

#+RESULTS:
[[file:compas_barplot_prot-sex_mod-dt_acc-pre-rec-f1.png]]

* Analysis of protected attribute =race=
In this section we expand & compare the metrics for the race
attribute.

#+begin_src python
  data = compas[compas['protected'] == 'race']
  data.shape
#+end_src

#+RESULTS:
| 15 | 33 |

** Analysis of fairness metrics

#+begin_src python :results file
  name = 'compas_barplot_prot-race_subset-all_num-pos-neg'

  fig, axs = plt.subplots(1, 2, sharey=True, figsize=(10, 5))

  sns.barplot(data=data,
	      y='num_positives',
	      x='subset',
	      hue='privileged',
	      hue_order=['None', 'True', 'False'],
	      ax=axs[0])

  for container in axs[0].containers:
      axs[0].bar_label(container)

  sns.barplot(data=data,
	      y='num_negatives',
	      x='subset',
	      hue='privileged',
	      hue_order=['None', 'True', 'False'],
	      ax=axs[1])

  for container in axs[1].containers:
      axs[1].bar_label(container)

  utils.savefig(fig, name)
#+end_src

#+RESULTS:
[[file:compas_barplot_prot-race_subset-all_num-pos-neg.png]]

#+begin_src python :results file
  name = 'compas_barplot_prot-race_subset-test_num-pos-neg'

  fig, axs = plt.subplots(1, 2, sharey=True, figsize=(10, 5))

  sns.barplot(data=data[data['subset'] == 'test'],
	      y='num_positives',
	      x='subset',
	      hue='privileged',
	      hue_order=['None', 'True', 'False'],
	      ax=axs[0])

  for container in axs[0].containers:
      axs[0].bar_label(container)

  sns.barplot(data=data[data['subset'] == 'test'],
	      y='num_negatives',
	      x='subset',
	      hue='privileged',
	      hue_order=['None', 'True', 'False'],
	      ax=axs[1])

  for container in axs[1].containers:
      axs[1].bar_label(container)

  utils.savefig(fig, name)
#+end_src

#+RESULTS:
[[file:compas_barplot_prot-race_subset-test_num-pos-neg.png]]

*** Analysis of =base_rate=

#+begin_src python :results file
  name = 'compas_barplot_prot-race_base-rate'

  fig, ax = plt.subplots()

  sns.barplot(data=data,
	      y='base_rate',
	      x='subset',
	      hue='privileged',
	      hue_order=['None', 'True', 'False'],
	      ax=ax)

  for container in ax.containers:
      ax.bar_label(container)

  utils.savefig(fig, name)

#+end_src

#+RESULTS:
[[file:compas_barplot_prot-race_base-rate.png]]

*** Analysis of =disparate_impact=

#+begin_src python :results file
  name = 'compas_barplot_prot-race_mod-none_disparate-impact'

  fig, ax = plt.subplots()

  sns.barplot(data=data[data['model'] == 'None'],
	      y='disparate_impact',
	      x='subset',
	      ax=ax)

  for container in ax.containers:
      ax.bar_label(container)

  utils.savefig(fig, name)
#+end_src

#+RESULTS:
[[file:compas_barplot_prot-race_mod-none_disparate-impact.png]]

#+begin_src python :results file
  name = 'compas_barplot_prot-race_mod-all_disparate-impact'

  fig, ax = plt.subplots()

  sns.barplot(data=data[data['subset'] == 'test'],
	      y='disparate_impact',
	      x='model',
	      ax=ax)

  for container in ax.containers:
      ax.bar_label(container)

  utils.savefig(fig, name)
#+end_src

#+RESULTS:
[[file:compas_barplot_prot-race_mod-all_disparate-impact.png]]

*** Analysis of =statistical_parity_difference=
#+begin_src python :results file
  name = 'compas_barplot_prot-race_mod-none_stat-par-diff'

  fig, ax = plt.subplots()

  sns.barplot(data=data[data['model'] == 'None'],
	      y='statistical_parity_difference',
	      x='subset',
	      ax=ax)

  for container in ax.containers:
      ax.bar_label(container)

  utils.savefig(fig, name)
#+end_src

#+RESULTS:
[[file:compas_barplot_prot-race_mod-none_stat-par-diff.png]]

#+begin_src python :results file
  name = 'compas_barplot_prot-race_mod-all_stat-par-diff'

  fig, ax = plt.subplots()

  sns.barplot(data=data[data['subset'] == 'test'],
	      y='statistical_parity_difference',
	      x='model',
	      ax=ax)

  for container in ax.containers:
      ax.bar_label(container)

  utils.savefig(fig, name)
#+end_src

#+RESULTS:
[[file:compas_barplot_prot-race_mod-all_stat-par-diff.png]]

** Analysis of performance metrics
*** model: logisticregression

#+begin_src python :results file
  name = 'compas_heatmap_prot-race_mod-lr_cm'
  metrics = data[data['model'] == 'logisticregression']
  cols = ['TN', 'FP', 'FN', 'TP']
  fig, axs = plt.subplots(1, 3, figsize=(15, 5))

  for idx, privileged in enumerate(['None', 'True', 'False']):
      cm = metrics[metrics['privileged'] == privileged]
      cm = cm[cols].values.reshape(2,2)
      sns.heatmap(data=cm,
		  annot=cm,
		  fmt="",
		  cbar=False,
		  cmap='Blues',
		  ax=axs[idx])
      axs[idx].set_xlabel("y_pred")
      axs[idx].set_ylabel("y_true")
      axs[idx].set_title(privileged)

  utils.savefig(fig, name)
#+end_src

#+RESULTS:
[[file:compas_heatmap_prot-race_mod-lr_cm.png]]

#+begin_src python :results file
  name = 'compas_heatmap_prot-race_mod-lr_cm-rate'
  metrics = data[data['model'] == 'logisticregression']
  cols = ['TNR', 'FPR', 'FNR', 'TPR']
  fig, axs = plt.subplots(1, 3, figsize=(15, 5))

  for idx, privileged in enumerate(['None', 'True', 'False']):
      cm = metrics[metrics['privileged'] == privileged]
      cm = cm[cols].values.reshape(2,2)
      sns.heatmap(data=cm,
		  annot=cm,
		  fmt=".3f",
		  cbar=False,
		  cmap='Blues',
		  ax=axs[idx])
      axs[idx].set_xlabel("y_pred")
      axs[idx].set_ylabel("y_true")
      axs[idx].set_title(privileged)

  utils.savefig(fig, name)
#+end_src

#+RESULTS:
[[file:compas_heatmap_prot-race_mod-lr_cm-rate.png]]

#+begin_src python :results file
  name = 'compas_barplot_prot-race_mod-lr_acc-pre-rec-f1'
  metrics = data[data['model'] == 'logisticregression']
  hue_order = ['None', 'True', 'False']

  fig, axs = plt.subplots(1, 4, sharey=True, figsize=(20, 5))

  sns.barplot(data=metrics,
	      y='accuracy',
	      x='subset',
	      hue='privileged',
	      hue_order=hue_order,
	      ax=axs[0])

  sns.barplot(data=metrics,
	      y='PPV',
	      x='subset',
	      hue='privileged',
	      hue_order=hue_order,
	      ax=axs[1])
  axs[1].set_ylabel('precision')

  sns.barplot(data=metrics,
	      y='TPR',
	      x='subset',
	      hue='privileged',
	      hue_order=hue_order,
	      ax=axs[2])
  axs[2].set_ylabel('recall')

  sns.barplot(data=metrics,
	      y='f1',
	      x='subset',
	      hue='privileged',
	      hue_order=hue_order,
	      ax=axs[3])

  for idx in range(4):
      for container in axs[idx].containers: axs[idx].bar_label(container)

  utils.savefig(fig, name)
#+end_src

#+RESULTS:
[[file:compas_barplot_prot-race_mod-lr_acc-pre-rec-f1.png]]

*** model: decisiontreeclassifier

#+begin_src python :results file
  name = 'compas_heatmap_prot-race_mod-dt_cm'
  metrics = data[data['model'] == 'decisiontreeclassifier']
  cols = ['TN', 'FP', 'FN', 'TP']
  fig, axs = plt.subplots(1, 3, figsize=(15, 5))

  for idx, privileged in enumerate(['None', 'True', 'False']):
      cm = metrics[metrics['privileged'] == privileged]
      cm = cm[cols].values.reshape(2,2)
      sns.heatmap(data=cm,
		  annot=cm,
		  fmt="",
		  cbar=False,
		  cmap='Blues',
		  ax=axs[idx])
      axs[idx].set_xlabel("y_pred")
      axs[idx].set_ylabel("y_true")
      axs[idx].set_title(privileged)

  utils.savefig(fig, name)
#+end_src

#+RESULTS:
[[file:compas_heatmap_prot-race_mod-dt_cm.png]]

#+begin_src python :results file
  name = 'compas_heatmap_prot-race_mod-dt_cm-rate'
  metrics = data[data['model'] == 'decisiontreeclassifier']
  cols = ['TNR', 'FPR', 'FNR', 'TPR']
  fig, axs = plt.subplots(1, 3, figsize=(15, 5))

  for idx, privileged in enumerate(['None', 'True', 'False']):
      cm = metrics[metrics['privileged'] == privileged]
      cm = cm[cols].values.reshape(2,2)
      sns.heatmap(data=cm,
		  annot=cm,
		  fmt=".3f",
		  cbar=False,
		  cmap='Blues',
		  ax=axs[idx])
      axs[idx].set_xlabel("y_pred")
      axs[idx].set_ylabel("y_true")
      axs[idx].set_title(privileged)

  utils.savefig(fig, name)
#+end_src

#+RESULTS:
[[file:compas_heatmap_prot-race_mod-dt_cm-rate.png]]

#+begin_src python :results file
  name = 'compas_barplot_prot-race_mod-dt_acc-pre-rec-f1'
  metrics = data[data['model'] == 'decisiontreeclassifier']
  hue_order = ['None', 'True', 'False']

  fig, axs = plt.subplots(1, 4, sharey=True, figsize=(20, 5))

  sns.barplot(data=metrics,
	      y='accuracy',
	      x='subset',
	      hue='privileged',
	      hue_order=hue_order,
	      ax=axs[0])

  sns.barplot(data=metrics,
	      y='PPV',
	      x='subset',
	      hue='privileged',
	      hue_order=hue_order,
	      ax=axs[1])
  axs[1].set_ylabel('precision')

  sns.barplot(data=metrics,
	      y='TPR',
	      x='subset',
	      hue='privileged',
	      hue_order=hue_order,
	      ax=axs[2])
  axs[2].set_ylabel('recall')

  sns.barplot(data=metrics,
	      y='f1',
	      x='subset',
	      hue='privileged',
	      hue_order=hue_order,
	      ax=axs[3])

  for idx in range(4):
      for container in axs[idx].containers: axs[idx].bar_label(container)

  utils.savefig(fig, name)
#+end_src

#+RESULTS:
[[file:compas_barplot_prot-race_mod-dt_acc-pre-rec-f1.png]]
